{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " # Plotting script"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script contains all the plotting code to generate different plots (listed under headers) used directly in the paper. It is overly verbose or inefficient at times (e.g. by recomputing predictions and bounding box intervals) and could be restructured or improved by leveraging precomputed results with filtering. However, it is very flexible and permits filtering results e.g. by ground truth matching, class name, set of classes etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import statements\n",
    "import sys\n",
    "sys.path.insert(0, \"/ssd_4TB/divake/conformal-od\")\n",
    "sys.path.insert(0, \"/ssd_4TB/divake/conformal-od/detectron2\")\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import importlib\n",
    "import argparse\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import beta\n",
    "from scipy.optimize import brentq\n",
    "import itertools\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.lines as mlines\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import FixedLocator, FixedFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from detectron2.data import MetadataCatalog, get_detection_dataset_dicts, DatasetCatalog\n",
    "from detectron2.data.detection_utils import annotations_to_instances\n",
    "from detectron2.structures import Instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "\n",
    "from control import std_conformal, ens_conformal, cqr_conformal, baseline_conformal, classifier_sets\n",
    "from data import data_loader\n",
    "from evaluation import results_table\n",
    "from model import matching, model_loader, ensemble_boxes_wbf\n",
    "from model.qr_head import QuantileROIHead\n",
    "from plots import plot_util\n",
    "from util import util, io_file\n",
    "\n",
    "from plots.plot_style import *\n",
    "\n",
    "# scientific notation off for pytorch\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_fig(figname: str, **kwargs):\n",
    "    # plt.savefig(figname + \".png\", dpi=300, format=\"png\", bbox_inches=\"tight\", **kwargs)\n",
    "    plt.savefig(figname + \".png\", format=\"png\", **kwargs)\n",
    "    print(f\"Saved figure {figname}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### simulate CLI with fixed parameters (see main.py for definitions)\n",
    "rc = \"std\" # ens, cqr\n",
    "d = \"coco_val\" \n",
    "\n",
    "args_dict = {\n",
    "    \"config_file\": f\"cfg_{rc}_rank\",\n",
    "    \"config_path\": f\"/ssd_4TB/divake/conformal-od/config/{d}\",\n",
    "    \"run_collect_pred\": False,\n",
    "    \"load_collect_pred\": f\"{rc}_conf_x101fpn_{rc}_rank_class\",\n",
    "    \"save_file_pred\": False,\n",
    "    \"risk_control\": f\"{rc}_conf\",\n",
    "    \"alpha\": 0.1,\n",
    "    \"label_set\": \"class_threshold\",\n",
    "    \"label_alpha\": 0.01,\n",
    "    \"run_risk_control\": True,\n",
    "    \"load_risk_control\": None,\n",
    "    \"save_file_control\": True,\n",
    "    \"save_label_set\": True,\n",
    "    \"run_eval\": True,\n",
    "    \"save_file_eval\": True,\n",
    "    \"file_name_prefix\": None,\n",
    "    \"file_name_suffix\": f\"_{rc}_rank_class\",\n",
    "    \"log_wandb\": False,\n",
    "    \"device\": \"cuda\"\n",
    "}\n",
    "args = argparse.Namespace(**args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "### main setup (see main.py)\n",
    "\n",
    "cfg = io_file.load_yaml(args.config_file, args.config_path, to_yacs=True)\n",
    "data_name = cfg.DATASETS.DATASET.NAME \n",
    "cfg.MODEL.AP_EVAL = False\n",
    "\n",
    "if args.file_name_prefix is not None:\n",
    "    file_name_prefix = args.file_name_prefix\n",
    "else:\n",
    "    file_name_prefix = (f\"{args.risk_control}_{cfg.MODEL.ID}{args.file_name_suffix}\")\n",
    "\n",
    "outdir = cfg.PROJECT.OUTPUT_DIR \n",
    "# NOTE: Modify as required\n",
    "outdir = f\"{outdir}\"\n",
    "\n",
    "filedir = os.path.join(outdir, data_name, file_name_prefix)\n",
    "Path(filedir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "logger = setup_logger(output=filedir)\n",
    "util.set_seed(cfg.PROJECT.SEED, logger=logger)\n",
    "cfg, _ = util.set_device(cfg, \"cpu\", logger=logger)\n",
    "\n",
    "if not DatasetCatalog.__contains__(data_name):\n",
    "    data_loader.d2_register_dataset(cfg, logger=logger)\n",
    "\n",
    "cfg_model, model = model_loader.d2_build_model(cfg, logger=logger)\n",
    "model_loader.d2_load_model(cfg_model, model, logger=logger)\n",
    "\n",
    "data_list = get_detection_dataset_dicts(data_name, filter_empty=cfg.DATASETS.DATASET.FILTER_EMPTY)\n",
    "dataloader = data_loader.d2_load_dataset_from_dict(data_list, cfg, cfg_model, logger=logger)\n",
    "metadata = MetadataCatalog.get(data_name).as_dict()\n",
    "nr_class = len(metadata[\"thing_classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Init risk control procedure with '{args.risk_control}'...\")\n",
    "if args.risk_control == \"std_conf\":\n",
    "    controller = std_conformal.StdConformal(\n",
    "        cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "    )\n",
    "elif args.risk_control == \"ens_conf\":\n",
    "    controller = ens_conformal.EnsConformal(\n",
    "        cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "    )\n",
    "elif args.risk_control == \"cqr_conf\":\n",
    "    controller = cqr_conformal.CQRConformal(\n",
    "        cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "    )\n",
    "elif args.risk_control == \"base_conf\":\n",
    "    controller = baseline_conformal.BaselineConformal(\n",
    "        cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load files\n",
    "# img_list = io_file.load_json(f\"{file_name_prefix}_img_list\", filedir)\n",
    "# ist_list = io_file.load_json(f\"{file_name_prefix}_ist_list\", filedir)\n",
    "control_data = io_file.load_tensor(f\"{file_name_prefix}_control\", filedir)\n",
    "test_indices = io_file.load_tensor(f\"{file_name_prefix}_test_idx\", filedir)\n",
    "label_data = io_file.load_tensor(f\"{file_name_prefix}_label\", filedir)\n",
    "# box_set_data = io_file.load_tensor(f\"{file_name_prefix}_box_set\", filedir)\n",
    "\n",
    "# plotting-specific details\n",
    "fnames = [data_list[i][\"file_name\"].split(\"/\")[-1][:-4] for i in range(len(data_list))]\n",
    "channels = cfg.DATASETS.DATASET.CHANNELS # type: ignore\n",
    "plotdir = os.path.join(\"plots\", data_name, file_name_prefix)\n",
    "Path(plotdir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "# get metric indices for easy access in loaded files\n",
    "from evaluation.results_table import _idx_metrics as metr\n",
    "from evaluation.results_table import _idx_label_metrics as label_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_classes = util.get_coco_classes()\n",
    "sel_coco_classes = util.get_selected_coco_classes()\n",
    "\n",
    "%pprint\n",
    "print(coco_classes)\n",
    "print(sel_coco_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Plot: image with ground truths or predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "### params\n",
    "class_name = \"person\" # gt contains instance of this class\n",
    "i, j = 0, 4 # desired score indices\n",
    "filter_for_class = True # filter for class_name\n",
    "###\n",
    "\n",
    "class_idx = metadata[\"thing_classes\"].index(class_name)\n",
    "cn = class_name.replace(\" \", \"\") # remove whitespace\n",
    "# select best trial idx for nice viz\n",
    "trial_idx = torch.argmin(control_data[:, class_idx, i:j, metr[\"mpiw\"]].mean(-1))\n",
    "# test img indices for that trial idx where class ist exists\n",
    "indices = torch.nonzero(test_indices[trial_idx, class_idx], as_tuple=True)[0].to(torch.float32)\n",
    "\n",
    "### select test img idx\n",
    "# -- random\n",
    "# idx = indices[torch.multinomial(indices, num_samples=1, replacement=False)]\n",
    "# -- by specific idx\n",
    "# idx = torch.tensor([76])\n",
    "# --by specific name\n",
    "idx = torch.tensor([fnames.index(\"000000054593\")])\n",
    "# \"zurich_000002_000019_leftImg8bit\"\n",
    "\n",
    "### select img\n",
    "img = dataloader.dataset.__getitem__(idx)\n",
    "img_id = os.path.split(img[\"file_name\"])[-1][:-4]\n",
    "\n",
    "### prediction\n",
    "pred = controller.raw_prediction(model, img)\n",
    "print(f\"Predicted for img {img_id} (idx {idx}) using {controller.__class__}\")\n",
    "\n",
    "### filtering\n",
    "if filter_for_class:\n",
    "    img[\"annotations\"] = [anno for anno in img[\"annotations\"] if anno[\"category_id\"] == class_idx]\n",
    "    print(f\"Filtered for class '{class_name}' only.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Ground truths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file = False\n",
    "\n",
    "col = \"red\"\n",
    "# list needs one color per object\n",
    "colors = [mcolors.to_rgb(col)]*len(img[\"annotations\"])\n",
    "fname = f\"tr{trial_idx}_{cn}_gt_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "plot_util.d2_plot_gt(img, metadata, channels, \n",
    "                          draw_labels=[], colors=colors, alpha=0.8, \n",
    "                          notebook=True, to_file=to_file, filename=os.path.join(plotdir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file = False\n",
    "\n",
    "col = \"blue\"\n",
    "# list needs one color per object\n",
    "colors = [mcolors.to_rgb(col)]*len(pred)\n",
    "fname = f\"tr{trial_idx}_{cn}_pred_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "print(\"######### All predictions:\")\n",
    "plot_util.d2_plot_pred(img, pred, metadata, channels, \n",
    "                          draw_labels=[], colors=colors, alpha=0.8, \n",
    "                          notebook=True, to_file=False, filename=os.path.join(plotdir, fname))\n",
    "\n",
    "print(f\"#########  Filtered predictions by class label '{class_name}':\")\n",
    "plot_util.d2_plot_pred(img, pred[pred.pred_classes == class_idx], metadata, channels, \n",
    "                          draw_labels=[], colors=colors, alpha=0.8, \n",
    "                          notebook=True, to_file=to_file, filename=os.path.join(plotdir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Predictions filtered by ground truth matching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt = annotations_to_instances(img[\"annotations\"], (img[\"height\"], img[\"width\"]))\n",
    "\n",
    "(\n",
    "    gt_box, pred_box, gt_class, pred_class, pred_score,\n",
    "    pred_score_all, pred_logits_all, matches\n",
    ") = matching.matching(\n",
    "    gt.gt_boxes, pred.pred_boxes, gt.gt_classes, pred.pred_classes, pred.scores, pred.scores_all, None,\n",
    "    controller.box_matching, controller.class_matching, controller.iou_thresh\n",
    ")\n",
    "\n",
    "pred_match = Instances(pred.image_size)\n",
    "pred_match.set(\"pred_boxes\", pred_box)\n",
    "pred_match.set(\"scores\", pred_score)\n",
    "pred_match.set(\"pred_classes\", pred_class)\n",
    "pred_match.set(\"pred_score_all\", pred_score_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file = False\n",
    "\n",
    "col = \"blue\"\n",
    "# list needs one color per object\n",
    "colors = [mcolors.to_rgb(col)]*len(pred)\n",
    "fname = f\"tr{trial_idx}_{cn}_gt_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "plot_util.d2_plot_pred(img, pred_match, metadata, channels, \n",
    "                          draw_labels=[], colors=colors, alpha=0.8, \n",
    "                          notebook=True, to_file=to_file, filename=os.path.join(plotdir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtered prediction and ground truth together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_match_gt = Instances(pred.image_size)\n",
    "\n",
    "# manual jitter for visualisation (if needed)\n",
    "# x0, y0, x1, y1\n",
    "pred_box_jit = pred_box.tensor + torch.tensor([[10, 0, -10, -10]])\n",
    "\n",
    "# Create a tensor of ones with the same length as gt_box (which is 6)\n",
    "gt_scores = torch.ones(len(gt_box))\n",
    "\n",
    "pred_match_gt.set(\"pred_boxes\", torch.cat([pred_box_jit, gt_box.tensor]))\n",
    "pred_match_gt.set(\"scores\", torch.cat([pred_score, gt_scores]))  # Now this will be length 12\n",
    "pred_match_gt.set(\"pred_classes\", torch.cat([pred_class, gt_class]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file = False\n",
    "\n",
    "color_gt = [mcolors.to_rgb(\"red\")]*len(img[\"annotations\"])\n",
    "color_pred = [mcolors.to_rgb(\"blue\")]*len(img[\"annotations\"])\n",
    "colors = color_gt + color_pred\n",
    "\n",
    "fname = f\"tr{trial_idx}_{cn}_gt_pred_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "print(\"######### Ground truth + prediction:\")\n",
    "plot_util.d2_plot_pred(img, pred_match_gt, metadata, channels, \n",
    "                          draw_labels=[], colors=colors, alpha=0.8, \n",
    "                          notebook=True, to_file=to_file, filename=os.path.join(plotdir, fname))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Plot: image with ground truth and PI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single image and method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "### params\n",
    "class_name = \"person\" # gt contains instance of this class\n",
    "i, j = 0, 4 # desired score indices\n",
    "filter_for_class = True # filter for class_name\n",
    "###\n",
    "\n",
    "class_idx = metadata[\"thing_classes\"].index(class_name)\n",
    "cn = class_name.replace(\" \", \"\") # remove whitespace\n",
    "# select best trial idx for nice viz\n",
    "trial_idx = torch.argmin(control_data[:, class_idx, i:j, metr[\"mpiw\"]].mean(-1))\n",
    "# test img indices for that trial idx where class ist exists\n",
    "indices = torch.nonzero(test_indices[trial_idx, class_idx], as_tuple=True)[0].to(torch.float32)\n",
    "\n",
    "### select test img idx\n",
    "# -- random\n",
    "# idx = indices[torch.multinomial(indices, num_samples=1, replacement=False)]\n",
    "# -- by specific idx\n",
    "# idx = torch.tensor([76])\n",
    "# --by specific name\n",
    "idx = torch.tensor([fnames.index(\"000000054593\")])\n",
    "# \"zurich_000002_000019_leftImg8bit\"\n",
    "\n",
    "### select img\n",
    "img = dataloader.dataset.__getitem__(idx)\n",
    "img_id = os.path.split(img[\"file_name\"])[-1][:-4]\n",
    "\n",
    "### prediction\n",
    "print(\"+++ Prediction procedure +++\")\n",
    "pred = controller.raw_prediction(model, img)\n",
    "print(f\"Predicted for img {img_id} (idx {idx}) using {controller.__class__}\")\n",
    "\n",
    "### filtering\n",
    "if filter_for_class:\n",
    "    img[\"annotations\"] = [anno for anno in img[\"annotations\"] if anno[\"category_id\"] == class_idx]\n",
    "    print(f\"Filtered for class '{class_name}' only.\")\n",
    "    # gt = annotations_to_instances(img[\"annotations\"], (img[\"height\"], img[\"width\"]))\n",
    "\n",
    "### matching\n",
    "gt = annotations_to_instances(img[\"annotations\"], (img[\"height\"], img[\"width\"]))\n",
    "\n",
    "(\n",
    "    gt_box, pred_box, gt_class, pred_class, pred_score, # type:ignore\n",
    "    pred_score_all, pred_logits_all, matches, _, pred_idx, _\n",
    ") = matching.matching(\n",
    "    gt.gt_boxes, pred.pred_boxes, gt.gt_classes, pred.pred_classes, pred.scores, \n",
    "    pred.scores_all, None,\n",
    "    controller.box_matching, controller.class_matching, controller.iou_thresh,\n",
    "    return_idx=True\n",
    ")\n",
    "print(f\"Performed matching using {controller.box_matching=} and {controller.class_matching=}.\")\n",
    "print(f\"Missed ground truth objects: {len(gt.gt_classes) - len(pred_idx)}/{len(gt.gt_classes)}.\\n\")\n",
    "\n",
    "### build matched prediction instance\n",
    "pred_match = Instances(pred.image_size)\n",
    "pred_match.set(\"pred_boxes\", pred_box)\n",
    "pred_match.set(\"scores\", pred_score)\n",
    "pred_match.set(\"pred_classes\", pred_class)\n",
    "pred_match.set(\"pred_score_all\", pred_score_all)\n",
    "\n",
    "if args.risk_control == \"ens_conf\":\n",
    "    pred_match.set(\"unc\", pred.unc[pred_idx])\n",
    "elif args.risk_control == \"cqr_conf\":\n",
    "    pred_lower = pred.get(f\"pred_boxes_{controller.q_str[controller.q_idx[0]]}\")\n",
    "    pred_upper = pred.get(f\"pred_boxes_{controller.q_str[controller.q_idx[1]]}\")\n",
    "    pred_match.set(\"pred_lower\", pred_lower[pred_idx])\n",
    "    pred_match.set(\"pred_upper\", pred_upper[pred_idx])\n",
    "\n",
    "### get quantiles for all classes, mean quantile over trials\n",
    "box_quant_all = control_data[:, :, i:j, metr[\"quant\"]].mean(dim=0)\n",
    "label_quant = label_data[:, :, label_metr[\"quant\"]].mean(dim=0)\n",
    "# true box quantiles\n",
    "box_quant_true = box_quant_all[gt_class]\n",
    "\n",
    "### get label set\n",
    "label_set = controller.label_set_generator.get_pred_set(pred_match.pred_score_all, label_quant)\n",
    "label_set = controller.label_set_generator.handle_null_set(pred_match.pred_score_all, label_set)\n",
    "\n",
    "print(\"+++ Label set procedure +++\")\n",
    "print(f\"Using method '{args.label_set}'.\")\n",
    "lab_gt, lab_pred, lab_set = [], [], []\n",
    "for i, labels in enumerate(label_set):\n",
    "    l_gt = coco_classes[gt_class[i]]\n",
    "    l_pred = coco_classes[pred_class[i]]\n",
    "    l_set = [coco_classes[l] for l in torch.nonzero(labels, as_tuple=True)[0]]\n",
    "    print(f\"True class: '{l_gt}' | Pred class: '{l_pred}' | Label set: {l_set}\")\n",
    "    lab_gt.append(l_gt); lab_pred.append(l_pred); lab_set.append(l_set)\n",
    "\n",
    "\n",
    "### get box set quantiles\n",
    "print(f\"Box quantile selection strategy: {controller.label_set_generator.box_set_strategy}.\")\n",
    "box_quant, box_quant_idx = classifier_sets.box_set_strategy(label_set, box_quant_all, controller.label_set_generator.box_set_strategy)\n",
    "\n",
    "b = box_quant_idx.tolist()\n",
    "l_box_quant = [[\"class\" for _ in range(4)] for _ in range(len(b))]\n",
    "for bi, bv in enumerate(b):\n",
    "    for bj, bv2 in enumerate(bv):\n",
    "        l_box_quant[bi][bj] = lab_set[bi][bv2] \n",
    "print(f\"Selected quantiles: {l_box_quant}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_file = False\n",
    "\n",
    "fname1 = f\"{args.risk_control}_{args.label_set}_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "fname2 = f\"{args.risk_control}_oracle_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "print(\"FIGURE 1: Label set quantiles\")\n",
    "plot_util.d2_plot_pi(args.risk_control, img, gt.gt_boxes, pred_match, box_quant,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir, fname1),\n",
    "                     label_gt=lab_gt, label_set=lab_set)\n",
    "\n",
    "print(\"FIGURE 2: Oracle (true class quantiles)\")\n",
    "plot_util.d2_plot_pi(args.risk_control, img, gt.gt_boxes, pred_match, box_quant_true,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir, fname2),\n",
    "                     label_gt=lab_gt, label_set=lab_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a single image and multiple methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_args(rc, d):\n",
    "    args_dict = {\n",
    "        \"config_file\": f\"cfg_{rc}_rank\",\n",
    "        \"config_path\": f\"/ssd_4TB/divake/conformal-od/config/{d}\",\n",
    "        \"run_collect_pred\": False,\n",
    "        \"load_collect_pred\": f\"{rc}_conf_x101fpn_{rc}_rank_class\",\n",
    "        \"save_file_pred\": False,\n",
    "        \"risk_control\": f\"{rc}_conf\",\n",
    "        \"alpha\": 0.1,\n",
    "        \"label_set\": \"class_threshold\",\n",
    "        \"label_alpha\": 0.01,\n",
    "        \"run_risk_control\": True,\n",
    "        \"load_risk_control\": None,\n",
    "        \"save_file_control\": True,\n",
    "        \"save_label_set\": True,\n",
    "        \"run_eval\": True,\n",
    "        \"save_file_eval\": True,\n",
    "        \"file_name_prefix\": None,\n",
    "        \"file_name_suffix\": f\"_{rc}_rank_class\",\n",
    "        \"log_wandb\": False,\n",
    "        \"device\": \"cpu\"\n",
    "    }\n",
    "    args = argparse.Namespace(**args_dict)\n",
    "    return args\n",
    "\n",
    "\n",
    "def get_dirs(args, cfg):\n",
    "    if args.file_name_prefix is not None:\n",
    "        file_name_prefix = args.file_name_prefix\n",
    "    else:\n",
    "        file_name_prefix = (f\"{args.risk_control}_{cfg.MODEL.ID}{args.file_name_suffix}\")\n",
    "    outdir = cfg.PROJECT.OUTPUT_DIR  # type: ignore\n",
    "    filedir = os.path.join(outdir, data_name, file_name_prefix)\n",
    "    Path(filedir).mkdir(exist_ok=True, parents=True)\n",
    "    return file_name_prefix, outdir, filedir\n",
    "\n",
    "\n",
    "def get_controller(args, cfg, nr_class, filedir, logger):\n",
    "    logger.info(f\"Init risk control procedure with '{args.risk_control}'...\")\n",
    "    if args.risk_control == \"std_conf\":\n",
    "        controller = std_conformal.StdConformal(\n",
    "            cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "        )\n",
    "    elif args.risk_control == \"ens_conf\":\n",
    "        controller = ens_conformal.EnsConformal(\n",
    "            cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "        )\n",
    "    elif args.risk_control == \"cqr_conf\":\n",
    "        controller = cqr_conformal.CQRConformal(\n",
    "            cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "        )\n",
    "    elif args.risk_control == \"base_conf\":\n",
    "        controller = baseline_conformal.BaselineConformal(\n",
    "            cfg, args, nr_class, filedir, log=None, logger=logger\n",
    "        )\n",
    "    return controller\n",
    "\n",
    "\n",
    "def get_loggy(plotdir_log, fname_log):\n",
    "    loggy = logging.getLogger('loggy')\n",
    "    loggy.setLevel(logging.DEBUG)\n",
    "    loggy.propagate = 0\n",
    "    file_handler = logging.FileHandler(os.path.join(plotdir_log, fname_log))\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(name)s|%(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    loggy.addHandler(file_handler)\n",
    "    loggy.addHandler(console_handler)\n",
    "    return loggy\n",
    "\n",
    "\n",
    "def update_log_path(loggy, new_path):\n",
    "    while len(loggy.handlers) > 0:\n",
    "        loggy.removeHandler(loggy.handlers[0])\n",
    "    file_handler = logging.FileHandler(new_path)\n",
    "    file_handler.setLevel(logging.DEBUG)\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(name)s|%(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "    loggy.addHandler(file_handler)\n",
    "    loggy.addHandler(console_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_name = \"coco_val\"\n",
    "args_std = get_args(\"std\", data_name)\n",
    "args_ens = get_args(\"ens\", data_name)\n",
    "args_cqr = get_args(\"cqr\", data_name)\n",
    "\n",
    "cfg_std = io_file.load_yaml(args_std.config_file, args_std.config_path, to_yacs=True)\n",
    "cfg_ens = io_file.load_yaml(args_ens.config_file, args_ens.config_path, to_yacs=True)\n",
    "cfg_cqr = io_file.load_yaml(args_cqr.config_file, args_cqr.config_path, to_yacs=True)\n",
    "\n",
    "# Update the checkpoint path to use absolute path\n",
    "cfg_cqr.MODEL.CHECKPOINT_PATH = os.path.join(os.getcwd(), \"../checkpoints/x101fpn_train_qr_5k_postprocess.pth\")\n",
    "\n",
    "file_name_prefix_std, outdir_std, filedir_std = get_dirs(args_std, cfg_std)\n",
    "file_name_prefix_ens, outdir_ens, filedir_ens = get_dirs(args_ens, cfg_ens)\n",
    "file_name_prefix_cqr, outdir_cqr, filedir_cqr = get_dirs(args_cqr, cfg_cqr)\n",
    "\n",
    "logger = setup_logger(output=filedir)\n",
    "util.set_seed(cfg_std.PROJECT.SEED, logger=logger)\n",
    "\n",
    "if not DatasetCatalog.__contains__(data_name):\n",
    "    data_loader.d2_register_dataset(cfg_std, logger=logger)\n",
    "\n",
    "cfg_model_std, model_std = model_loader.d2_build_model(cfg_std, logger=logger)\n",
    "model_loader.d2_load_model(cfg_model_std, model_std, logger=logger)\n",
    "cfg_model_ens, model_ens = model_loader.d2_build_model(cfg_ens, logger=logger)\n",
    "model_loader.d2_load_model(cfg_model_ens, model_ens, logger=logger)\n",
    "cfg_model_cqr, model_cqr = model_loader.d2_build_model(cfg_cqr, logger=logger)\n",
    "model_loader.d2_load_model(cfg_model_cqr, model_cqr, logger=logger)\n",
    "\n",
    "data_list = get_detection_dataset_dicts(data_name, filter_empty=cfg.DATASETS.DATASET.FILTER_EMPTY)\n",
    "dataloader = data_loader.d2_load_dataset_from_dict(data_list, cfg_std, cfg_model_std, logger=logger)\n",
    "metadata = MetadataCatalog.get(data_name).as_dict()\n",
    "nr_class = len(metadata[\"thing_classes\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "controller_std = get_controller(args_std, cfg_std, nr_class, filedir_std, logger)\n",
    "controller_ens = get_controller(args_ens, cfg_ens, nr_class, filedir_ens, logger)\n",
    "controller_cqr = get_controller(args_cqr, cfg_cqr, nr_class, filedir_cqr, logger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_data_std = io_file.load_tensor(f\"{file_name_prefix_std}_control\", filedir_std)\n",
    "test_indices_std = io_file.load_tensor(f\"{file_name_prefix_std}_test_idx\", filedir_std)\n",
    "label_data_std = io_file.load_tensor(f\"{file_name_prefix_std}_label\", filedir_std)\n",
    "\n",
    "control_data_ens = io_file.load_tensor(f\"{file_name_prefix_ens}_control\", filedir_ens)\n",
    "test_indices_ens = io_file.load_tensor(f\"{file_name_prefix_ens}_test_idx\", filedir_ens)\n",
    "label_data_ens = io_file.load_tensor(f\"{file_name_prefix_ens}_label\", filedir_ens)\n",
    "\n",
    "control_data_cqr = io_file.load_tensor(f\"{file_name_prefix_cqr}_control\", filedir_cqr)\n",
    "test_indices_cqr = io_file.load_tensor(f\"{file_name_prefix_cqr}_test_idx\", filedir_cqr)\n",
    "label_data_cqr = io_file.load_tensor(f\"{file_name_prefix_cqr}_label\", filedir_cqr)\n",
    "\n",
    "# plotting-specific details\n",
    "fnames = [data_list[i][\"file_name\"].split(\"/\")[-1][:-4] for i in range(len(data_list))]\n",
    "channels = cfg.DATASETS.DATASET.CHANNELS # type: ignore\n",
    "\n",
    "plotdir_std = os.path.join(\"plots\", data_name, file_name_prefix_std)\n",
    "Path(plotdir_std).mkdir(exist_ok=True, parents=True)\n",
    "plotdir_ens = os.path.join(\"plots\", data_name, file_name_prefix_ens)\n",
    "Path(plotdir_ens).mkdir(exist_ok=True, parents=True)\n",
    "plotdir_cqr = os.path.join(\"plots\", data_name, file_name_prefix_cqr)\n",
    "Path(plotdir_cqr).mkdir(exist_ok=True, parents=True)\n",
    "plotdir_log = os.path.join(\"plots\", data_name, \"logs\")\n",
    "Path(plotdir_log).mkdir(exist_ok=True, parents=True)\n",
    "loggy = get_loggy(plotdir_log, \"log.txt\")\n",
    "\n",
    "# get metric indices for easy access in loaded files\n",
    "from evaluation.results_table import _idx_metrics as metr\n",
    "from evaluation.results_table import _idx_label_metrics as label_metr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(args, controller, model, img, img_id, idx, filter_for_class, filter_for_set, class_name, set_name,\n",
    "             set_idx, control_data, label_data, i, j, metr, label_metr, coco_classes, loggy):\n",
    "\n",
    "    ### prediction\n",
    "    loggy.info(\"+++ Prediction procedure +++\")\n",
    "    pred = controller.raw_prediction(model, img)\n",
    "    loggy.info(f\"Predicted for img {img_id} (idx {idx}) using {controller.__class__}\")\n",
    "\n",
    "    ### filtering\n",
    "    if filter_for_class:\n",
    "        img[\"annotations\"] = [anno for anno in img[\"annotations\"] if anno[\"category_id\"] == class_idx]\n",
    "        loggy.info(f\"Filtered for class '{class_name}' only.\")\n",
    "        # gt = annotations_to_instances(img[\"annotations\"], (img[\"height\"], img[\"width\"]))\n",
    "    elif filter_for_set:\n",
    "        img[\"annotations\"] = [anno for anno in img[\"annotations\"] if anno[\"category_id\"] in set_idx]\n",
    "        loggy.info(f\"Filtered for classes {set_name} only.\")\n",
    "\n",
    "    ### matching\n",
    "    gt = annotations_to_instances(img[\"annotations\"], (img[\"height\"], img[\"width\"]))\n",
    "\n",
    "    (\n",
    "        gt_box, pred_box, gt_class, pred_class, pred_score, # type:ignore\n",
    "        pred_score_all, pred_logits_all, matches, _, pred_idx, _\n",
    "    ) = matching.matching(\n",
    "        gt.gt_boxes, pred.pred_boxes, gt.gt_classes, pred.pred_classes, pred.scores, \n",
    "        pred.scores_all, None,\n",
    "        controller.box_matching, controller.class_matching, controller.iou_thresh,\n",
    "        return_idx=True\n",
    "    )\n",
    "    loggy.info(f\"Performed matching using {controller.box_matching=} and {controller.class_matching=}.\")\n",
    "    loggy.info(f\"Missed ground truth objects: {len(gt.gt_classes) - len(pred_idx)}/{len(gt.gt_classes)}.\\n\")\n",
    "\n",
    "    ### build matched prediction instance\n",
    "    pred_match = Instances(pred.image_size)\n",
    "    pred_match.set(\"pred_boxes\", pred_box)\n",
    "    pred_match.set(\"scores\", pred_score)\n",
    "    pred_match.set(\"pred_classes\", pred_class)\n",
    "    pred_match.set(\"pred_score_all\", pred_score_all)\n",
    "\n",
    "    if args.risk_control == \"ens_conf\":\n",
    "        pred_match.set(\"unc\", pred.unc[pred_idx])\n",
    "    elif args.risk_control == \"cqr_conf\":\n",
    "        pred_lower = pred.get(f\"pred_boxes_{controller.q_str[controller.q_idx[0]]}\")\n",
    "        pred_upper = pred.get(f\"pred_boxes_{controller.q_str[controller.q_idx[1]]}\")\n",
    "        pred_match.set(\"pred_lower\", pred_lower[pred_idx])\n",
    "        pred_match.set(\"pred_upper\", pred_upper[pred_idx])\n",
    "\n",
    "    ### get quantiles for all classes, mean quantile over trials\n",
    "    box_quant_all = control_data[:, :, i:j, metr[\"quant\"]].mean(dim=0)\n",
    "    label_quant = label_data[:, :, label_metr[\"quant\"]].mean(dim=0)\n",
    "    # true box quantiles\n",
    "    box_quant_true = box_quant_all[gt_class]\n",
    "\n",
    "    ### get label set\n",
    "    label_set = controller.label_set_generator.get_pred_set(pred_match.pred_score_all, label_quant)\n",
    "    label_set = controller.label_set_generator.handle_null_set(pred_match.pred_score_all, label_set)\n",
    "\n",
    "    loggy.info(\"+++ Label set procedure +++\")\n",
    "    loggy.info(f\"Using method '{args.label_set}'.\")\n",
    "    lab_gt, lab_pred, lab_set = [], [], []\n",
    "    for i, labels in enumerate(label_set):\n",
    "        l_gt = coco_classes[gt_class[i]]\n",
    "        l_pred = coco_classes[pred_class[i]]\n",
    "        l_set = [coco_classes[l] for l in torch.nonzero(labels, as_tuple=True)[0]]\n",
    "        loggy.info(f\"True class: '{l_gt}' | Pred class: '{l_pred}' | Label set: {l_set}\")\n",
    "        lab_gt.append(l_gt); lab_pred.append(l_pred); lab_set.append(l_set)\n",
    "\n",
    "    ### get box set quantiles\n",
    "    loggy.info(f\"Box quantile selection strategy: {controller.label_set_generator.box_set_strategy}.\")\n",
    "    box_quant, box_quant_idx = classifier_sets.box_set_strategy(label_set, box_quant_all, controller.label_set_generator.box_set_strategy)\n",
    "    \n",
    "    b = box_quant_idx.tolist()\n",
    "    l_box_quant = [[\"class\" for _ in range(4)] for _ in range(len(b))]\n",
    "    for bi, bv in enumerate(b):\n",
    "        for bj, bv2 in enumerate(bv):\n",
    "            l_box_quant[bi][bj] = lab_set[bi][bv2] \n",
    "    loggy.info(f\"Selected quantiles: {l_box_quant}\")\n",
    "\n",
    "    return gt, pred_match, box_quant, box_quant_true, lab_gt, lab_pred, lab_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(coco_classes)\n",
    "sel_coco_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "### params\n",
    "plot_name = \"000000054593\"  # The specific COCO image ID you want to use\n",
    "class_name = \"person\"  # Filter for this class\n",
    "set_name = []  # Not filtering for a set of classes\n",
    "i, j = 0, 4  # Desired score indices\n",
    "filter_for_class = True  # Filter for class_name\n",
    "filter_for_set = False  # Not filtering for a set\n",
    "device = \"cpu\"  # Force CPU usage\n",
    "\n",
    "###\n",
    "# Move all tensors to CPU\n",
    "control_data_std = control_data_std.to(device)\n",
    "control_data_ens = control_data_ens.to(device)\n",
    "control_data_cqr = control_data_cqr.to(device)\n",
    "test_indices_std = test_indices_std.to(device)\n",
    "\n",
    "if filter_for_class:\n",
    "    class_idx = metadata[\"thing_classes\"].index(class_name)\n",
    "    cn = class_name.replace(\" \", \"\")  # Remove whitespace\n",
    "    # Select best trial idx for nice viz\n",
    "    trial_idx_std = torch.argmin(control_data_std[:, class_idx, i:j, metr[\"mpiw\"]].mean(-1))\n",
    "    trial_idx_ens = torch.argmin(control_data_ens[:, class_idx, i:j, metr[\"mpiw\"]].mean(-1))\n",
    "    trial_idx_cqr = torch.argmin(control_data_cqr[:, class_idx, i:j, metr[\"mpiw\"]].mean(-1))\n",
    "    # Test img indices for that trial idx where class exists\n",
    "    indices = torch.nonzero(test_indices_std[trial_idx_std, class_idx], as_tuple=True)[0].to(torch.float32)\n",
    "    set_idx = []\n",
    "elif filter_for_set:\n",
    "    set_idx = [metadata[\"thing_classes\"].index(n) for n in set_name]\n",
    "    cn = \"set\"\n",
    "else:\n",
    "    cn = \"all\"\n",
    "\n",
    "### Find the index of the specific image\n",
    "# Instead of iterating through the whole dataset, let's use a more direct approach\n",
    "# If you know the image ID is 000000054593, you might be able to use a more direct method\n",
    "# For COCO dataset, the index might be directly related to the image ID\n",
    "target_idx = 477  # You mentioned this was the index in your error message\n",
    "\n",
    "# Set the index to the specific image\n",
    "idx = torch.tensor([target_idx], device=device)\n",
    "\n",
    "### Select img\n",
    "img = dataloader.dataset.__getitem__(idx)\n",
    "img_id = os.path.splitext(os.path.basename(img[\"file_name\"]))[0]\n",
    "\n",
    "fname_log = f\"all_{args_std.label_set}_{cn}_idx{idx.numpy()[0]}_img{img_id}.log\"\n",
    "update_log_path(loggy, os.path.join(plotdir_log, fname_log))\n",
    "\n",
    "# Make sure the models are on CPU\n",
    "model_std.to(device)\n",
    "model_ens.to(device)\n",
    "model_cqr.to(device)\n",
    "\n",
    "# Define a wrapper for get_pred to ensure everything stays on CPU\n",
    "def get_pred_cpu(*args, **kwargs):\n",
    "    # Move any tensor inputs to CPU\n",
    "    new_args = []\n",
    "    for arg in args:\n",
    "        if isinstance(arg, torch.Tensor):\n",
    "            new_args.append(arg.to(device))\n",
    "        else:\n",
    "            new_args.append(arg)\n",
    "    \n",
    "    # Call the original function\n",
    "    results = get_pred(*new_args, **kwargs)\n",
    "    \n",
    "    # Ensure all tensor outputs are on CPU\n",
    "    cpu_results = []\n",
    "    for res in results:\n",
    "        if isinstance(res, torch.Tensor):\n",
    "            cpu_results.append(res.to(device))\n",
    "        else:\n",
    "            cpu_results.append(res)\n",
    "    \n",
    "    return tuple(cpu_results)\n",
    "\n",
    "### Prediction\n",
    "loggy.info(f\"------ Method: {args_std.risk_control} ------\")\n",
    "gt_std, pred_match_std, box_quant_std, box_quant_true_std, lab_gt_std, lab_pred_std, lab_set_std = get_pred_cpu(\n",
    "    args_std, controller_std, model_std, img, img_id, idx, filter_for_class, filter_for_set, class_name, set_name, set_idx,\n",
    "    control_data_std, label_data_std, i, j, metr, label_metr, coco_classes, loggy \n",
    ")\n",
    "\n",
    "loggy.info(f\"\\n------ Method: {args_ens.risk_control} ------\")\n",
    "gt_ens, pred_match_ens, box_quant_ens, box_quant_true_ens, lab_gt_ens, lab_pred_ens, lab_set_ens = get_pred_cpu(\n",
    "    args_ens, controller_ens, model_ens, img, img_id, idx, filter_for_class, filter_for_set, class_name, set_name, set_idx,\n",
    "    control_data_ens, label_data_ens, i, j, metr, label_metr, coco_classes, loggy \n",
    ")\n",
    "\n",
    "loggy.info(f\"\\n------ Method: {args_cqr.risk_control} ------\")\n",
    "gt_cqr, pred_match_cqr, box_quant_cqr, box_quant_true_cqr, lab_gt_cqr, lab_pred_cqr, lab_set_cqr = get_pred_cpu(\n",
    "    args_cqr, controller_cqr, model_cqr, img, img_id, idx, filter_for_class, filter_for_set, class_name, set_name, set_idx,\n",
    "    control_data_cqr, label_data_cqr, i, j, metr, label_metr, coco_classes, loggy \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_file = True\n",
    "to_file = False\n",
    "\n",
    "fname_std = f\"{args_std.risk_control}_{args_std.label_set}_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "fname_ens = f\"{args_ens.risk_control}_{args_ens.label_set}_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "fname_cqr = f\"{args_cqr.risk_control}_{args_cqr.label_set}_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "print(f\"FIG 1.1: Label set quant; {args_std.risk_control} - {args_std.label_set}\\n\")\n",
    "plot_util.d2_plot_pi(args_std.risk_control, img, gt_std.gt_boxes, pred_match_std, box_quant_std,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir_std, fname_std),\n",
    "                     label_gt=lab_gt_std, label_set=lab_set_std)\n",
    "\n",
    "print(f\"FIG 1.2: Label set quant; {args_ens.risk_control} - {args_ens.label_set}\\n\")\n",
    "plot_util.d2_plot_pi(args_ens.risk_control, img, gt_ens.gt_boxes, pred_match_ens, box_quant_ens,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir_ens, fname_ens),\n",
    "                     label_gt=lab_gt_ens, label_set=lab_set_ens)\n",
    "\n",
    "print(f\"FIG 1.3: Label set quant; {args_cqr.risk_control} - {args_cqr.label_set}\\n\")\n",
    "plot_util.d2_plot_pi(args_cqr.risk_control, img, gt_cqr.gt_boxes, pred_match_cqr, box_quant_cqr,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir_cqr, fname_cqr),\n",
    "                     label_gt=lab_gt_cqr, label_set=lab_set_cqr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_file = True\n",
    "# to_file = False\n",
    "\n",
    "fname_std = f\"{args_std.risk_control}_oracle_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "fname_ens = f\"{args_ens.risk_control}_oracle_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "fname_cqr = f\"{args_cqr.risk_control}_oracle_{cn}_idx{idx.numpy()[0]}_img{img_id}.jpg\"\n",
    "\n",
    "print(f\"FIG 2.1: Oracle; {args_std.risk_control}\\n\")\n",
    "plot_util.d2_plot_pi(args_std.risk_control, img, gt_std.gt_boxes, pred_match_std, box_quant_true_std,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir_std, fname_std),\n",
    "                     label_gt=lab_gt_std, label_set=lab_set_std)\n",
    "\n",
    "print(f\"FIG 2.2: Oracle; {args_ens.risk_control}\\n\")\n",
    "plot_util.d2_plot_pi(args_ens.risk_control, img, gt_ens.gt_boxes, pred_match_ens, box_quant_true_ens,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir_ens, fname_ens),\n",
    "                     label_gt=lab_gt_ens, label_set=lab_set_ens)\n",
    "\n",
    "print(f\"FIG 2.3: Oracle; {args_cqr.risk_control}\\n\")\n",
    "plot_util.d2_plot_pi(args_cqr.risk_control, img, gt_cqr.gt_boxes, pred_match_cqr, box_quant_true_cqr,\n",
    "                     channels, draw_labels=[], \n",
    "                     colors=[\"red\", \"green\", \"palegreen\"], alpha=[1.0, 0.6, 0.4],\n",
    "                     lw=1.5, notebook=True, to_file=to_file,\n",
    "                     filename=os.path.join(plotdir_cqr, fname_cqr),\n",
    "                     label_gt=lab_gt_cqr, label_set=lab_set_cqr)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Plot: empirical coverage histogram over nr. of trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "### params\n",
    "class_name = \"car\"\n",
    "i, j = 0, 4 # desired score indices\n",
    "alpha = 0.1 # miscoverage\n",
    "###\n",
    "\n",
    "n = 1000 # calibration samples\n",
    "a, b = n + 1 - np.floor((n+1)*alpha), np.floor((n+1)*alpha) # beta shape params\n",
    "x = np.linspace(beta.ppf(0, a, b), beta.ppf(1, a, b), 1000)\n",
    "\n",
    "class_idx = metadata[\"thing_classes\"].index(class_name)\n",
    "cn = class_name.replace(\" \", \"\") # remove whitespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# coordinate coverage for all trials\n",
    "cover = control_data[:, class_idx, i:j, metr[\"cov_coord\"]]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(5, 3))\n",
    "labs = [\"x0\", \"y0\", \"x1\", \"y1\"]\n",
    "\n",
    "for i, ax in enumerate(axes.flat):\n",
    "    cov = cover[:, i]\n",
    "    ax.hist(cov.numpy(), bins=30, alpha=0.5, range=(0.85, 1.0),\n",
    "            color=\"blue\", density=True,\n",
    "            label=r\"Emp. coverage, $\\bar{x}$ = \" + f\"{cov.mean():.3f}\")\n",
    "    ax.plot(x, beta.pdf(x, a, b), color=\"red\", alpha=0.8,\n",
    "            label = f\"Nom. Beta fit, {n} samp\")\n",
    "            # label=f\"Beta({int(a)},{int(b)})\")\n",
    "    ax.axvline(x=1-alpha, color=\"black\", ls=\":\", label=r\"Nom. coverage 1-$\\alpha$\")\n",
    "    ax.set_xlim(0.85, 1.0)\n",
    "    ax.legend(loc=\"upper left\", fontsize=\"small\") # large\n",
    "    ax.set_ylabel(\"Density\", fontsize=\"small\")\n",
    "    ax.set_xlabel(\"Coverage level\", fontsize=\"small\")\n",
    "    ax.set_title(f\"Coord. {labs[i]}\", fontsize=\"small\")\n",
    "fig.suptitle(f\"Class: {class_name}, Coverage histogram over nr. of trials\", \n",
    "             y=.97, x=0.5, fontsize=\"medium\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# save_fig(plotdir, f\"{class_name}_emp_coord_cov_hist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# box coverage for all trials\n",
    "cov = control_data[:, class_idx, i, metr[\"cov_box\"]]\n",
    "\n",
    "fig, ax = plt.subplots(1, 1, figsize=(5, 3))\n",
    "ax.hist(cov.numpy(), bins=30, alpha=0.5, range=(0.8, 1.0),\n",
    "        color=\"blue\", density=True,\n",
    "        label=r\"Emp. coverage, $\\bar{x}$ = \" + f\"{cov.mean():.3f}\")\n",
    "ax.plot(x, beta.pdf(x, a, b), color=\"red\", alpha=0.8,\n",
    "        label = f\"Nom. Beta fit, {n} samp\")\n",
    "        # label=f\"Beta({int(a)},{int(b)})\")\n",
    "ax.axvline(x=1-alpha, color=\"black\", ls=\":\", label=r\"Nom. coverage 1-$\\alpha$\")\n",
    "ax.set_xlim(0.84, 0.96)\n",
    "ax.legend(loc=\"upper left\", fontsize=\"small\") # large\n",
    "ax.set_ylabel(\"Density\", fontsize=\"small\")\n",
    "ax.set_xlabel(\"Coverage level\", fontsize=\"small\")\n",
    "ax.set_title(f\"Class: {class_name}, Box coverage histogram over nr. of trials\", fontsize=\"small\")\n",
    "fig.tight_layout()\n",
    "\n",
    "# save_fig(plotdir, f\"{class_name}_emp_box_cov_hist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: Beta distribution for given calibration set size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "eps = 0.03\n",
    "ql, qh = 0.01, 0.99\n",
    "qs = []\n",
    "\n",
    "calib_sizes = [930, 3100, 56000]\n",
    "dataset = [\"COCO\", \"Cityscapes\", \"BDD100k\"]\n",
    "colors = [\"#a7c957\", \"#219EBC\", \"#E63946\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.2, 2.2))\n",
    "\n",
    "for i, n in enumerate(calib_sizes):\n",
    "  \n",
    "  # compute cov beta distr\n",
    "  l = np.floor((n+1)*alpha)\n",
    "  a = n + 1 - l\n",
    "  b = l\n",
    "  x = np.linspace(1-alpha-eps, 1-alpha+eps, 10000)\n",
    "  rv = beta(a, b)\n",
    "  \n",
    "  # compute beta quantile\n",
    "  q_low = rv.ppf(ql)\n",
    "  q_high = rv.ppf(qh)\n",
    "  ax.vlines(q_low, ymin=0, ymax=rv.pdf(q_low), lw=1.5, color=colors[i])\n",
    "  ax.vlines(q_high, ymin=0, ymax=rv.pdf(q_high), lw=1.5, color=colors[i])\n",
    "  \n",
    "  # plot with two-line legend\n",
    "  ax.plot(x, rv.pdf(x), lw=1.5, label=f'{dataset[i]} (n = {n})', color=colors[i])\n",
    "  ax.plot([], [], alpha=0, label=rf'$Q_{{{ql}}}$ = {q_low:.3f}, $Q_{{{qh}}}$ = {q_high:.3f}')\n",
    "  ax.fill_between(x, rv.pdf(x), where = (x >= q_low) & (x <= q_high), alpha=0.2, color=colors[i], interpolate=True)\n",
    "  \n",
    "  qs.append((f\"{q_low:.3f}\", f\"{q_high:.3f}\"))\n",
    "\n",
    "ax.vlines(1-alpha, ymin=0, ymax=ax.get_ylim()[1], lw=1.5, ls='--', label=r'Target coverage ($1 - \\alpha_B$)', color=\"black\")\n",
    "\n",
    "ax.set_xlabel(r'Coverage', fontsize=12)\n",
    "ax.set_ylabel(r'Density', fontsize=12)\n",
    "# ax.set_title(r'Nominal coverage distribution', fontsize=14)\n",
    "ax.set_ylim(0, 320)\n",
    "ax.set_xlim(1-alpha-eps, 1-alpha+eps)\n",
    "\n",
    "leg = ax.legend(loc=\"upper left\", fontsize=7)\n",
    "leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "leg.get_frame().set_alpha(1.0)\n",
    "\n",
    "plt.xticks(fontsize=7)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.tight_layout()\n",
    "# save_fig(f\"plots/calib_size_cov_distr_box\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Quantiles for target coverage {1 - alpha}: \\nq_low={ql}, q_high={qh} \\n{qs}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.01\n",
    "eps = 0.01\n",
    "ql, qh = 0.01, 0.99\n",
    "qs = []\n",
    "\n",
    "calib_sizes = [930, 3100, 56000]\n",
    "dataset = [\"COCO\", \"Cityscapes\", \"BDD100k\"]\n",
    "colors = [\"#a7c957\", \"#219EBC\", \"#E63946\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.2, 2.2))\n",
    "\n",
    "for i, n in enumerate(calib_sizes):\n",
    "  \n",
    "  # compute cov beta distr\n",
    "  l = np.floor((n+1)*alpha)\n",
    "  a = n + 1 - l\n",
    "  b = l\n",
    "  x = np.linspace(1-alpha-eps, 1-alpha+eps, 10000)\n",
    "  rv = beta(a, b)\n",
    "  \n",
    "  # compute beta quantile\n",
    "  q_low = rv.ppf(ql)\n",
    "  q_high = rv.ppf(qh)\n",
    "  ax.vlines(q_low, ymin=0, ymax=rv.pdf(q_low), lw=1.5, color=colors[i])\n",
    "  ax.vlines(q_high, ymin=0, ymax=rv.pdf(q_high), lw=1.5, color=colors[i])\n",
    "  \n",
    "  # plot with two-line legend\n",
    "  ax.plot(x, rv.pdf(x), lw=1.5, label=f'{dataset[i]} (n = {n})', color=colors[i])\n",
    "  ax.plot([], [], alpha=0, label=rf'$Q_{{{ql}}}$ = {q_low:.3f}, $Q_{{{qh}}}$ = {q_high:.3f}')\n",
    "  ax.fill_between(x, rv.pdf(x), where = (x >= q_low) & (x <= q_high), alpha=0.2, color=colors[i], interpolate=True)\n",
    "  \n",
    "  qs.append((f\"{q_low:.3f}\", f\"{q_high:.3f}\"))\n",
    "\n",
    "ax.vlines(1-alpha, ymin=0, ymax=ax.get_ylim()[1], lw=1.5, ls='--', label=r'Target coverage ($1 - \\alpha_L$)', color=\"black\")\n",
    "\n",
    "ax.set_xlabel(r'Coverage', fontsize=12)\n",
    "ax.set_ylabel(r'Density', fontsize=12)\n",
    "# ax.set_title(r'Nominal coverage distribution', fontsize=14)\n",
    "ax.set_ylim(0, 960)\n",
    "ax.set_xlim(1-alpha-eps, 1-alpha+eps)\n",
    "\n",
    "leg = ax.legend(loc=\"upper left\", fontsize=7)\n",
    "leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "leg.get_frame().set_alpha(1.0)\n",
    "\n",
    "plt.xticks(fontsize=7)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.tight_layout()\n",
    "# save_fig(f\"plots/calib_size_cov_distr_labels\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Quantiles for target coverage {1 - alpha}: \\nq_low={ql}, q_high={qh} \\n{qs}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- compute exact calibration set sizes required for desired condition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# see https://github.com/aangelopoulos/conformal-prediction/blob/main/notebooks/correctness_checks.ipynb\n",
    "\n",
    "alpha = 0.1\n",
    "epsilons = [0.0165, 0.0089, 0.00209]\n",
    "\n",
    "for epsilon in epsilons:\n",
    "  def _condition(n):\n",
    "    l = np.floor((n+1)*alpha)\n",
    "    a = n + 1 - l\n",
    "    b = l\n",
    "    if (beta.ppf(0.05, a, b) < 1-alpha-epsilon) or (beta.ppf(0.95, a, b) > 1-alpha+epsilon):\n",
    "      return -1\n",
    "    else:\n",
    "      return 1\n",
    "\n",
    "  print(int(np.ceil(brentq(_condition,np.ceil(1/alpha),100000000000))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Plot: Main results, efficiency vs. coverage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Label set names\n",
    "- match: box metrics for calibration samples with class matching and correct quantile selection (original), no label set procedure\n",
    "- plain: box metrics for calibration samples without class matching but with correct quantile selection, no label set procedure\n",
    "- full: box metrics for calibration samples without class matching and for full label sets\n",
    "- top: box metrics for calibration samples without class matching and for top label sets\n",
    "- oracle: box metrics for calibration samples without class matching and for density level label sets \n",
    "- class: box metrics for calibration samples without class matching and for class label sets (per-class thresholding)\n",
    "\n",
    "Renaming (in line with the paper):\n",
    "- Match --> OracleMatch (not reported in the paper)\n",
    "- Plain --> Oracle\n",
    "- Oracle --> Naive\n",
    "- Class --> ClassThr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- For box set metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only for single type at a time\n",
    "t = \"rank\" # rank, bonf \n",
    "\n",
    "# datasets\n",
    "datasets = [\"coco_val\", \"cityscapes\", \"bdd100k_train\"]\n",
    "\n",
    "res_folder = f\"results/results_selected_{t}\"\n",
    "plot_folder = \"plots/results_selected\"\n",
    "Path(plot_folder).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "label_paths = []\n",
    "box_paths = []\n",
    "for d in datasets:\n",
    "    label_paths.append(f\"{res_folder}/{d}_res_{t}_label_table.csv\")\n",
    "    box_paths.append(f\"{res_folder}/{d}_res_{t}_box_set_table.csv\")\n",
    "\n",
    "print(\"Loading results from:\", res_folder, \"\\n\", \"Plotting figures to:\", plot_folder)\n",
    "print(\"Label result files:\", label_paths, \"\\n\", \"Box result files:\", box_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Names\n",
    "conf_str = [\"Box-Std\", \"Box-Ens\", \"Box-CQR\"]\n",
    "label_str = [\"Full\", \"Top\", \"Naive\", \"ClassThr\"]\n",
    "label_plain = \"Oracle\"\n",
    "label_match = \"OracleMatch\"\n",
    "\n",
    "# for latex rendering\n",
    "dataset_str = {\"coco_val\": \"cocoval\", \"cityscapes\": \"cityscapes\", \"bdd100k_train\": \"bdd100ktrain\"}\n",
    "\n",
    "# Emp coverage\n",
    "alpha = 0.9\n",
    "# 1 and 99 percent quantiles of empirical beta distr based on calibration set size (see above)\n",
    "emp_cov_lim = {\"coco_val\": (0.876, 0.922), \"cityscapes\": (0.887, 0.912), \"bdd100k_train\": (0.897, 0.903)}\n",
    "\n",
    "# Plotting \n",
    "markers = {label_plain: \"o\", label_str[0]: \"s\", label_str[1]: \"^\", label_str[2]: \"P\", label_str[3]: \"*\"}\n",
    "\n",
    "# colors = {conf_str[0]: \"red\", conf_str[1]: \"green\", conf_str[2]: \"cornflowerblue\"}\n",
    "# colors = {conf_str[0]: \"#BC4749\", conf_str[1]: \"#A7C957\", conf_str[2]: \"#386641\"}\n",
    "colors = {conf_str[0]: \"#E63946\", conf_str[1]: \"#219EBC\", conf_str[2]: \"#023047\"}\n",
    "\n",
    "xaxis_lim = {\"coco_val\": (0.87, 1.003), \"cityscapes\": (0.878, 1.003), \"bdd100k_train\": (0.878, 1.003)}\n",
    "yaxis_lim = {\"coco_val\": (40, 260), \"cityscapes\": (45, 220), \"bdd100k_train\": (30, 230)}\n",
    "yaxis_ticks = {\n",
    "    \"coco_val\": [50, 75, 100, 125, 150, 175, 200, 225, 250],\n",
    "    \"cityscapes\": [50, 75, 100, 125, 150, 175, 200],\n",
    "    \"bdd100k_train\": [50, 75, 100, 125, 150, 175, 200, 225]\n",
    "}\n",
    "figheight = {\"coco_val\": 1.85, \"cityscapes\": 1.85, \"bdd100k_train\": 2.0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 1 \n",
    "i, path = idx, box_paths[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, path in enumerate(box_paths):\n",
    "\n",
    "df = pd.read_csv(box_paths[i])\n",
    "df = df[df[\"label\"] != label_match]\n",
    "\n",
    "conf = df[\"conf\"].to_list()\n",
    "label = df[\"label\"].to_list()\n",
    "mpiw = df[\"mpiw\"].to_list()\n",
    "cov = df[\"cov box\"].to_list()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4.5, figheight[datasets[i]]))\n",
    "leg_mark, leg_name = [], []\n",
    "\n",
    "for j, c in enumerate(conf):\n",
    "    a = ax.scatter(cov[j], mpiw[j], marker=markers[label[j]], color=colors[conf[j]], linewidth=1, s=48)\n",
    "    leg_mark.append([a])\n",
    "    leg_name.append([f\"{conf[j]}, {label[j]}\"])\n",
    "\n",
    "leg_mark = np.array(leg_mark).flatten()\n",
    "leg_name = np.array(leg_name).flatten()\n",
    "\n",
    "# first legend outside plot\n",
    "# leg = ax.legend(leg_mark, leg_name, ncol=3, loc=\"center\", bbox_to_anchor=(0.5, 1.35), fontsize=8) # legend below plot\n",
    "# # leg = ax.legend(leg_mark, leg_name, ncol=3, loc=\"upper left\") # legend inside plot\n",
    "# leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "# leg.get_frame().set_alpha(1.0)\n",
    "# ax.add_artist(leg)\n",
    "\n",
    "# target cov\n",
    "ax.axvline(x=alpha, color=\"black\", linestyle=\"--\", label=r'Target coverage')\n",
    "liml, limh = emp_cov_lim[datasets[i]]\n",
    "ax.axvspan(liml, limh, alpha=0.2, color=\"grey\")\n",
    "# ax.axvline(x=liml, color=\"grey\", linestyle=\"--\", label=r'Coverage distr. $Q_{0.01}$')\n",
    "# ax.axvline(x=limh, color=\"grey\", linestyle=\"--\", label=r'Coverage distr. $Q_{0.99}$')\n",
    "\n",
    "ax.set_ylabel(r'MPIW', fontsize=14)\n",
    "ax.set_xlabel(r'Box coverage', fontsize=14)\n",
    "ax.yaxis.set_major_locator(FixedLocator(yaxis_ticks[datasets[i]]))\n",
    "ax.xaxis.grid(False, which=\"major\")\n",
    "ax.set_xlim(xaxis_lim[datasets[i]])\n",
    "ax.set_ylim(yaxis_lim[datasets[i]])\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save_fig(f\"{plot_folder}/{datasets[i]}_{t}_box_set\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "--- For label set metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Coverage\n",
    "alpha_lab = 0.99\n",
    "# 1 and 99 percent quantiles of empirical beta distr based on calibration set size (see above)\n",
    "emp_cov_lim_lab = {\"coco_val\": (0.981, 0.996), \"cityscapes\": (0.985, 0.994), \"bdd100k_train\": (0.989, 0.991)}\n",
    "\n",
    "# Plotting\n",
    "markers_lab = {label_str[0]: \"s\", label_str[1]: \"^\", label_str[2]: \"P\", label_str[3]: \"*\"}\n",
    "\n",
    "xaxis_lim = {\"coco_val\": (0.913, 1.003), \"cityscapes\": (0.915, 1.003), \"bdd100k_train\": (0.819, 1.006)}\n",
    "xaxis_ticks = {\n",
    "    \"coco_val\": [0.92, 0.94, 0.96, 0.98, 1.00],\n",
    "    \"cityscapes\": [0.92, 0.94, 0.96, 0.98, 1.00],\n",
    "    \"bdd100k_train\": [0.82, 0.84, 0.86, 0.88, 0.90, 0.92, 0.94, 0.96, 0.98, 1.00]\n",
    "}\n",
    "figheight = {\"coco_val\": 1.7, \"cityscapes\": 1.7, \"bdd100k_train\": 1.7}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 2 \n",
    "i, path = idx, label_paths[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "plot with y-axis break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i, path in enumerate(label_paths):\n",
    "\n",
    "df = pd.read_csv(label_paths[i])\n",
    "\n",
    "conf = df[\"conf\"].to_list()\n",
    "label = df[\"label\"].to_list()\n",
    "mss = df[\"mean set size\"].to_list()\n",
    "cov = df[\"cov set\"].to_list()\n",
    "\n",
    "# jitter coverage to visualize in plot\n",
    "cov_jit = []\n",
    "for ji, v in enumerate(cov):\n",
    "    if conf[ji] == \"Box-CQR\":\n",
    "        jv = v-0.001\n",
    "    elif conf[ji] == \"Box-Std\" and label[ji] == \"Full\":\n",
    "        jv = v+0.001\n",
    "    else:\n",
    "        jv = v\n",
    "    cov_jit.append(jv)\n",
    "cov = cov_jit\n",
    "\n",
    "fig = plt.figure(figsize=(4.5, figheight[datasets[i]]))\n",
    "gs = matplotlib.gridspec.GridSpec(2, 1, height_ratios=[1, 4], hspace=0.15)\n",
    "ax1 = fig.add_subplot(gs[0]) # Top plot\n",
    "ax2 = fig.add_subplot(gs[1]) # Bottom plot\n",
    "\n",
    "leg_mark, leg_name = [], []\n",
    "\n",
    "for j, c in enumerate(conf):\n",
    "    if label[j] == \"Full\": \n",
    "        # Top plot\n",
    "        a = ax1.scatter(cov[j], mss[j], marker=markers_lab[label[j]], color=colors[conf[j]], linewidth=1, s=48)\n",
    "    else: \n",
    "        # Bottom plot\n",
    "        a = ax2.scatter(cov[j], mss[j], marker=markers_lab[label[j]], color=colors[conf[j]], linewidth=1, s=48)\n",
    "    \n",
    "    leg_mark.append([a])\n",
    "    leg_name.append([f\"{conf[j]}, {label[j]}\"])\n",
    "\n",
    "# Draw break\n",
    "d = .012\n",
    "kwargs = dict(transform=ax1.transAxes, color='k', clip_on=False)\n",
    "ax1.plot((-d, +d), (-d, +d), **kwargs)        # top-left diagonal\n",
    "ax1.plot((1 - d, 1 + d), (-d, +d), **kwargs)  # top-right diagonal\n",
    "kwargs.update(transform=ax2.transAxes)  # switch to the bottom subplot's coordinate system\n",
    "ax2.plot((-d, +d), (1 - d, 1 + d), **kwargs)  # bottom-left diagonal\n",
    "ax2.plot((1 - d, 1 + d), (1 - d, 1 + d), **kwargs)  # bottom-right diagonal\n",
    "\n",
    "# target cov\n",
    "ax1.axvline(x=alpha_lab, color=\"black\", linestyle=\"--\", label=r'Target coverage')\n",
    "ax2.axvline(x=alpha_lab, color=\"black\", linestyle=\"--\", label=r'Target coverage')     \n",
    "# emp cov limits\n",
    "liml, limh = emp_cov_lim_lab[datasets[i]]\n",
    "ax1.axvspan(liml, limh, alpha=0.2, color=\"grey\")\n",
    "ax2.axvspan(liml, limh, alpha=0.2, color=\"grey\")\n",
    "# ax1.axvline(x=liml, color=\"grey\", linestyle=\"--\", label=r'Coverage distr. $Q_{0.01}$')\n",
    "# ax1.axvline(x=limh, color=\"grey\", linestyle=\"--\", label=r'Coverage distr. $Q_{0.99}$')\n",
    "\n",
    "# Legend for cov inside plot\n",
    "# leg2 = ax2.legend(fontsize=8)\n",
    "# leg2.get_frame().set_facecolor(\"white\")\n",
    "# leg2.get_frame().set_alpha(1.0)\n",
    "# ax2.add_artist(leg2)\n",
    "\n",
    "# Legend\n",
    "# leg_mark = np.array(leg_mark).flatten()\n",
    "# leg_name = np.array(leg_name).flatten()\n",
    "# leg = ax2.legend(leg_mark, leg_name, ncol=3, loc=\"center\", bbox_to_anchor=(0.5, -1.15), fontsize=8) # legend below plot\n",
    "# # leg = ax1.legend(leg_mark, leg_name, ncol=3, loc=\"upper left\") # legend inside plot\n",
    "# leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "# leg.get_frame().set_alpha(1.0)\n",
    "\n",
    "ax1.spines['bottom'].set_color(\"lightgray\")\n",
    "ax1.spines['bottom'].set_alpha(0.5)\n",
    "ax2.spines['top'].set_color(\"lightgray\")\n",
    "ax2.spines['top'].set_alpha(0.5)\n",
    "\n",
    "ax1.xaxis.set_ticks_position('none')\n",
    "ax1.set_xticklabels([])\n",
    "ax2.set_xlim(xaxis_lim[datasets[i]])\n",
    "ax2.set_xticks(xaxis_ticks[datasets[i]])\n",
    "ax1.set_xlim(ax2.get_xlim()) # align top x-axis with bottom one\n",
    "\n",
    "ax1.set_yticks([80])\n",
    "ax1.set_yticklabels([80], fontsize=8)\n",
    "ax2.set_yticks([1, 2, 3, 4])\n",
    "ax2.set_yticklabels([1, 2, 3, 4], fontsize=8)\n",
    "ax2.set_ylim(0.7, 4)\n",
    "\n",
    "fig.text(0.03, 0.5, r'Mean set size', ha='center', va='center', rotation='vertical', fontsize=14)\n",
    "ax2.set_xlabel(r'Label coverage', fontsize=14)\n",
    "ax1.xaxis.grid(False, which=\"major\")\n",
    "ax2.xaxis.grid(False, which=\"major\")\n",
    "plt.xticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save_fig(f\"{plot_folder}/{datasets[i]}_{t}_label\")\n",
    "\n",
    "plt.show()\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: ClassThr and Naive vs. calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive label set\n",
    "filedir = \"output/coco_val/std_conf_x101fpn_std_rank_oracle_temp\"\n",
    "df_box_set = pd.read_csv(f'{filedir}/box_metrics_per_temp.csv')\n",
    "df_label_set = pd.read_csv(f'{filedir}/label_metrics_per_temp.csv')\n",
    "\n",
    "# Class threshold label set\n",
    "filedir_cl = \"output/coco_val/std_conf_x101fpn_std_rank_class_temp\"\n",
    "df_box_set_cl = pd.read_csv(f'{filedir_cl}/box_metrics_per_temp.csv')\n",
    "df_label_set_cl = pd.read_csv(f'{filedir_cl}/label_metrics_per_temp.csv')\n",
    "\n",
    "# ECE vs. temperature (same for naive and class)\n",
    "filedir_ece = \"output/coco_val/std_conf_x101fpn_std_rank_class_temp\"\n",
    "df_ece_per_temp = pd.read_csv(f'{filedir_ece}/ece_per_temp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_cols = [\"mpiw\", \"box stretch\", \"cov box\"]\n",
    "label_cols = [\"mean set size\", \"cov set\"]\n",
    "\n",
    "metr_str = {\"mpiw\": \"MPIW\", \n",
    "            \"box stretch\": \"Box stretch\", \n",
    "            \"cov box\": \"Box coverage\", \n",
    "            \"mean set size\": \"Mean set size\", \n",
    "            \"cov set\": \"Label coverage\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LABEL SET\n",
    "df1 = df_label_set\n",
    "df2 = df_label_set_cl\n",
    "metric = \"cov set\"\n",
    "metric2 = \"mean set size\"\n",
    "save_str = \"label_metrics\"\n",
    "cover = 0.99\n",
    "\n",
    "# BOX SET\n",
    "# df1 = df_box_set\n",
    "# df2 = df_box_set_cl\n",
    "# metric = \"cov box\"\n",
    "# metric2 = \"mpiw\"\n",
    "# save_str = \"box_metrics\"\n",
    "# cover = 0.9\n",
    "\n",
    "metric_col = \"#E63946\"\n",
    "metric2_col = \"#219EBC\" #\"#023047\" #\"#3D9970\" #\"#219EBC\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values\n",
    "ece = df1[\"ece\"].to_numpy()\n",
    "metr = df1[metric].to_numpy()\n",
    "metr2 = df1[metric2].to_numpy()\n",
    "metr_cl = df2[metric].to_numpy()\n",
    "metr2_cl = df2[metric2].to_numpy()\n",
    "\n",
    "temp = df1[\"temperature\"].to_numpy()\n",
    "temp_val = 1.3 # 1.0\n",
    "idx_temp = df1.loc[df1['temperature'] == temp_val].index[0]\n",
    "ece_at_temp = df_ece_per_temp[df_ece_per_temp[\"temperature\"] == temp_val][\"ece\"].item()\n",
    "\n",
    "ece_overconf = ece[:idx_temp+1][::-1]\n",
    "metr_overconf = metr[:idx_temp+1][::-1]\n",
    "metr2_overconf = metr2[:idx_temp+1][::-1]\n",
    "metr_overconf_cl = metr_cl[:idx_temp+1][::-1]\n",
    "metr2_overconf_cl = metr2_cl[:idx_temp+1][::-1]\n",
    "\n",
    "ece_underconf = ece[idx_temp:]\n",
    "metr_underconf = metr[idx_temp:]\n",
    "metr2_underconf = metr2[idx_temp:]\n",
    "metr_underconf_cl = metr_cl[idx_temp:]\n",
    "metr2_underconf_cl = metr2_cl[idx_temp:]\n",
    "\n",
    "# Figure\n",
    "fig = plt.figure(figsize=(5, 4))\n",
    "gs = gridspec.GridSpec(2, 2, height_ratios=[1, 4])\n",
    "ax0 = fig.add_subplot(gs[0, :])\n",
    "ax1 = fig.add_subplot(gs[1, 0])\n",
    "ax2 = fig.add_subplot(gs[1, 1])\n",
    "\n",
    "# Plot 0\n",
    "ax0.plot(df_ece_per_temp[\"temperature\"], df_ece_per_temp[\"ece\"], color=\"#E63946\", ls=\"-\", marker='o', alpha=0.8)\n",
    "ax0.set_xlabel('Temperature', fontsize=12, labelpad=-4)\n",
    "ax0.set_ylabel('ECE', fontsize=12)\n",
    "ax0.set_ylim(-0.1, 1.1)\n",
    "ax0.set_xscale('log')\n",
    "ax0.axvline(x=temp_val, color=\"black\", ls=\":\", lw=2, label=rf'Opt. confidence ($T^*={temp_val}$, $ECE={round(ece_at_temp*100, 2)}\\%$)')\n",
    "ax0.legend()\n",
    "ax0.text(0.17, 0.5, r'$\\leftarrow$ +Overconfidence', fontsize=8, va='center', color=\"black\", weight=\"extra bold\")\n",
    "ax0.text(1.47, 0.5, r'+Underconfidence $\\rightarrow$', fontsize=8, va='center', color=\"black\", weight=\"extra bold\")\n",
    "\n",
    "# Plot 1\n",
    "ax1.plot(ece_overconf, metr_overconf, ls=\"-\", marker='o', color=metric_col, alpha=0.8, label=\"Naive\")\n",
    "ax1.plot(ece_overconf, metr_overconf_cl, ls=\"--\", marker='s', color=metric_col, alpha=0.8, label=\"ClassThr\")\n",
    "ax1.axvline(x=ece[idx_temp], color=\"black\", ls=\"-.\", lw=1.5, label=rf'ECE at $T^*={temp_val}$')\n",
    "ax1.axhline(y=cover, color=\"black\", ls=\":\", lw=1.5, label=rf'Target cov. ($1-\\alpha$)')\n",
    "ax1.set_xlabel(r'+Overconfidence $\\rightarrow$', fontsize=12)\n",
    "ax1.set_ylabel(f'{metr_str[metric]}', fontsize=12, color=metric_col)\n",
    "\n",
    "# Plot 1 - twin axis\n",
    "ax1_x2 = ax1.twinx()\n",
    "ax1_x2.plot(ece_overconf, metr2_overconf, ls=\"-\", marker='o', color=metric2_col, alpha=0.8)\n",
    "ax1_x2.plot(ece_overconf, metr2_overconf_cl, ls=\"--\", marker='s', color=metric2_col, alpha=0.8)\n",
    "ax1_x2.grid(False)\n",
    "ax1_x2.set_ylim(-1.5, 81.5)\n",
    "\n",
    "# Plot 2\n",
    "ax2.plot(ece_underconf, metr_underconf, ls=\"-\", marker='o', color=metric_col, alpha=0.8, label=\"Naive\")\n",
    "ax2.plot(ece_underconf, metr_underconf_cl, ls=\"--\", marker='s', color=metric_col, alpha=0.8, label=\"Naive\")\n",
    "ax2.axvline(x=ece[idx_temp], color=\"black\", ls=\"-.\", lw=1.5, label=rf'ECE at $T^*={temp_val}$')\n",
    "ax2.axhline(y=cover, color=\"black\", ls=\":\", lw=1.5, label=rf'Target cov. ($1-\\alpha$)')\n",
    "ax2.set_xlabel(r'+Underconfidence $\\rightarrow$', fontsize=12)\n",
    "ax2.set_xscale('log')\n",
    "\n",
    "# Plot 2 - twin axis\n",
    "ax2_x2 = ax2.twinx() # create a second y-axis on the right side of the plot\n",
    "ax2_x2.plot(ece_underconf, metr2_underconf, ls=\"-\", marker='o', color=metric2_col, alpha=0.8)\n",
    "ax2_x2.plot(ece_underconf, metr2_underconf_cl, ls=\"--\", marker='s', color=metric2_col, alpha=0.8)\n",
    "ax2_x2.set_ylabel(f'{metr_str[metric2]}', fontsize=12, color=metric2_col)\n",
    "ax2_x2.grid(False)\n",
    "ax2_x2.set_ylim(-1.5, 81.5)\n",
    "\n",
    "# Plot 1 - custom legend\n",
    "ax1naive = mlines.Line2D([], [], color='grey', ls=\"-\", marker='o', label='Naive')\n",
    "ax1class = mlines.Line2D([], [], color='grey', ls=\"--\", marker='s', label='ClassThr')\n",
    "ax1vline = mlines.Line2D([], [], color='black', ls=\"-.\", lw=1, label='Opt. confidence')\n",
    "ax1hline = mlines.Line2D([], [], color='black', ls=\":\", lw=1, label='Target coverage')\n",
    "leg1 = ax1_x2.legend(handles=[ax1naive, ax1class, ax1hline, ax1vline], loc=\"center\")\n",
    "leg1.get_frame().set_facecolor(\"white\")\n",
    "leg1.get_frame().set_alpha(1.0)\n",
    "\n",
    "# Plot 2 - custom legend\n",
    "# leg2 = ax2.legend(fontsize=7)\n",
    "# ax2naive = mlines.Line2D([], [], color='grey', marker='o', ls=\"-\", label='Naive')\n",
    "# ax2class = mlines.Line2D([], [], color='grey', marker='o', ls=\"--\", label='ClassThr')\n",
    "# ax2vline = mlines.Line2D([], [], color='black', ls=\":\", label=rf'ECE at $T^*={temp_val}$')\n",
    "# leg2 = ax2.legend(handles=[ax2naive, ax2class, ax2vline])\n",
    "# leg2.get_frame().set_facecolor(\"white\")\n",
    "# leg2.get_frame().set_alpha(1.0)\n",
    "\n",
    "# Figure\n",
    "# fig.suptitle('Label set strategy vs. calibration', fontsize=14)\n",
    "plt.xticks(fontsize=7)\n",
    "plt.yticks(fontsize=7)\n",
    "plt.tight_layout()\n",
    "# save_fig(f\"plots/{save_str}_vs_ece\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: Coverage (stratified) across methods, MPIW across methods; violin plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"cityscapes\"\n",
    "classes = list(util.get_selected_coco_classes().values())\n",
    "i, j = 0, 4 # score indices\n",
    "\n",
    "plot_dir = \"plots/violins\"\n",
    "Path(plot_dir).mkdir(exist_ok=True, parents=True)\n",
    "\n",
    "emp_cov_lim = {\"coco_val\": (0.876, 0.922), \"cityscapes\": (0.887, 0.912), \"bdd100k_train\": (0.897, 0.903)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_std = io_file.load_tensor(\"std_conf_x101fpn_std_rank_control\", f\"output/{dataset}/std_conf_x101fpn_std_rank\")\n",
    "data_ens = io_file.load_tensor(\"ens_conf_x101fpn_ens_rank_control\", f\"output/{dataset}/ens_conf_x101fpn_ens_rank\")\n",
    "data_cqr = io_file.load_tensor(\"cqr_conf_x101fpn_cqr_rank_control\", f\"output/{dataset}/cqr_conf_x101fpn_cqr_rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_table._idx_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check\n",
    "print(\"Cov | Cov_S | Cov_M | Cov_L\")\n",
    "print(data_std[:, classes, i:j].mean(dim=(1,2))[:, 5:9].mean(dim=0))\n",
    "print(data_ens[:, classes, i:j].mean(dim=(1,2))[:, 5:9].mean(dim=0))\n",
    "print(data_cqr[:, classes, i:j].mean(dim=(1,2))[:, 5:9].mean(dim=0))\n",
    "\n",
    "print(\"\\nMPIW\")\n",
    "print(data_std[:, classes, i:j].mean(dim=(1,2))[:, 2].mean(dim=0))\n",
    "print(data_ens[:, classes, i:j].mean(dim=(1,2))[:, 2].mean(dim=0))\n",
    "print(data_cqr[:, classes, i:j].mean(dim=(1,2))[:, 2].mean(dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_std = data_std[:, classes, i:j].nanmean(dim=(1,2))[:, 5].numpy()\n",
    "cov_s_std = data_std[:, classes, i:j].nanmean(dim=(1,2))[:, 6].numpy()\n",
    "cov_m_std = data_std[:, classes, i:j].nanmean(dim=(1,2))[:, 7].numpy()\n",
    "cov_l_std = data_std[:, classes, i:j].nanmean(dim=(1,2))[:, 8].numpy()\n",
    "mpiw_std = data_std[:, classes, i:j].nanmean(dim=(1,2))[:, 2].numpy()\n",
    "\n",
    "cov_ens = data_ens[:, classes, i:j].nanmean(dim=(1,2))[:, 5].numpy()\n",
    "cov_s_ens = data_ens[:, classes, i:j].nanmean(dim=(1,2))[:, 6].numpy()\n",
    "cov_m_ens = data_ens[:, classes, i:j].nanmean(dim=(1,2))[:, 7].numpy()\n",
    "cov_l_ens = data_ens[:, classes, i:j].nanmean(dim=(1,2))[:, 8].numpy()\n",
    "mpiw_ens = data_ens[:, classes, i:j].nanmean(dim=(1,2))[:, 2].numpy()\n",
    "\n",
    "cov_cqr = data_cqr[:, classes, i:j].nanmean(dim=(1,2))[:, 5].numpy()\n",
    "cov_s_cqr = data_cqr[:, classes, i:j].nanmean(dim=(1,2))[:, 6].numpy()\n",
    "cov_m_cqr = data_cqr[:, classes, i:j].nanmean(dim=(1,2))[:, 7].numpy()\n",
    "cov_l_cqr = data_cqr[:, classes, i:j].nanmean(dim=(1,2))[:, 8].numpy()\n",
    "mpiw_cqr = data_cqr[:, classes, i:j].nanmean(dim=(1,2))[:, 2].numpy()\n",
    "\n",
    "# replace nan values\n",
    "if dataset == \"coco_val\":\n",
    "    cov_s_ens = np.nan_to_num(cov_s_ens, nan=np.nanmedian(cov_s_ens))\n",
    "if dataset == \"cityscapes\":\n",
    "    cov_s_std = np.nan_to_num(cov_s_std, nan=np.nanmedian(cov_s_std))\n",
    "    cov_s_ens = np.nan_to_num(cov_s_ens, nan=np.nanmedian(cov_s_ens))\n",
    "    cov_s_cqr = np.nan_to_num(cov_s_cqr, nan=np.nanmedian(cov_s_cqr))\n",
    "if dataset == \"bdd100k_train\":\n",
    "    cov_s_ens = np.nan_to_num(cov_s_ens, nan=np.nanmedian(cov_s_ens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5, 3))\n",
    "\n",
    "ax.axhline(y=0.9, color=\"black\", linestyle=\"--\", label=r'Target coverage (1 - $\\alpha_B$)')\n",
    "\n",
    "col = [\"#E63946\", \"#219EBC\", \"#023047\", \"#BC4749\"]\n",
    "# colors = {conf_str[0]: \"#BC4749\", conf_str[1]: \"#A7C957\", conf_str[2]: \"#386641\"}\n",
    "xt = [1, 2, 3, 4]\n",
    "\n",
    "data = [cov_std, cov_s_std, cov_m_std, cov_l_std]\n",
    "means = [d.mean() for d in data]\n",
    "violin = ax.violinplot(data, showextrema=False, widths=0.3, points=1000)\n",
    "\n",
    "for i, body in enumerate(violin[\"bodies\"]):\n",
    "    body.set_facecolor(col[i])\n",
    "    body.set_edgecolor(\"black\")\n",
    "    body.set_alpha(0.8)\n",
    "    body.set_linewidth(1)\n",
    "    \n",
    "    # horizontal mean lines\n",
    "    path = body.get_paths()[0].to_polygons()[0]\n",
    "    ax.plot([min(path[:,0])+0.01, max(path[:,0])-0.01], [means[i], means[i]], color=\"black\", linestyle=\"-\", linewidth=1)\n",
    "    \n",
    "ax.set_title(\"Violin plot\")\n",
    "\n",
    "ax.set_ylabel(\"Coverage\")\n",
    "ax.set_ylim(0.64, 1.01)\n",
    "ax.set_yticks(np.arange(0.65, 1.01, 0.05))\n",
    "\n",
    "ax.set_xlabel(\"Method\")\n",
    "ax.set_xticks(xt)\n",
    "ax.set_xticklabels([\"$Cov$\", \"$Cov_S$\", \"$Cov_M$\", \"$Cov_L$\"])\n",
    "ax.set_xlim(0.5, 4.5)\n",
    "\n",
    "ax.legend(loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"#E63946\", \"#219EBC\", \"#023047\", \"#A7C957\"]\n",
    "# colors = {conf_str[0]: \"#BC4749\", conf_str[1]: \"#A7C957\", conf_str[2]: \"#386641\"}\n",
    "\n",
    "y_lims = {\"coco_val\": (0.64, 1.02), \"cityscapes\": (0.64, 1.02), \"bdd100k_train\": (0.68, 1.02)}\n",
    "y_lims_ticks = {\"coco_val\": [0.7, 0.8, 0.9, 1.0], \"cityscapes\": [0.7, 0.8, 0.9, 1.0], \"bdd100k_train\": [0.7, 0.8, 0.9, 1.0]}\n",
    "# leg_loc = {\"coco_val\": (0.55, 0.04)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(5.5, 1.45))\n",
    "\n",
    "ax.axhline(y=0.9, color=\"black\", linestyle=\"--\", label=r'Target coverage (1 - $\\alpha_B$)')\n",
    "liml, limh = emp_cov_lim[dataset]\n",
    "# ax.axhline(y=liml, color=\"grey\", linestyle=\"-\", label=r'Coverage distr. $Q_{0.01}$')\n",
    "# ax.axhline(y=limh, color=\"grey\", linestyle=\"-\", label=r'Coverage distr. $Q_{0.99}$')\n",
    "ax.axhspan(liml, limh, alpha=0.3, color=\"grey\", label=r'Coverage distribution')\n",
    "\n",
    "data = [cov_std, cov_s_std, cov_m_std, cov_l_std, cov_ens, cov_s_ens, cov_m_ens, cov_l_ens, cov_cqr, cov_s_cqr, cov_m_cqr, cov_l_cqr]\n",
    "means = [d.mean() for d in data]\n",
    "offsets = [1, 2, 3, 4, 7, 8, 9, 10, 13, 14, 15, 16]\n",
    "violin = ax.violinplot(data, showextrema=False, widths=0.5, points=1000, positions=offsets)\n",
    "\n",
    "for i, body in enumerate(violin[\"bodies\"]):\n",
    "    body.set_facecolor(col[i % len(col)])\n",
    "    body.set_edgecolor(\"black\")\n",
    "    body.set_alpha(0.8)\n",
    "    body.set_linewidth(1)\n",
    "    \n",
    "    # horizontal mean lines\n",
    "    path = body.get_paths()[0].to_polygons()[0]\n",
    "    ax.plot([min(path[:,0])+0.01, max(path[:,0])-0.01], [means[i], means[i]], color=\"black\", linestyle=\"-\", linewidth=1)\n",
    "\n",
    "ax.set_ylabel(\"Coverage\", fontsize=12)\n",
    "ax.set_ylim(y_lims[dataset])\n",
    "ax.set_yticks(y_lims_ticks[dataset])\n",
    "\n",
    "major_ticks = [2.5, 8.5, 14.5]\n",
    "major_labels = [\"Box-Std\", \"Box-Ens\", \"Box-CQR\"]\n",
    "\n",
    "minor_ticks = [1, 2, 3, 4, 7, 8, 9, 10, 13, 14, 15, 16]\n",
    "# minor_labels = [\"$Cov$\", \"$Cov_S$\", \"$Cov_M$\", \"$Cov_L$\"] * 3\n",
    "minor_labels = [\"All\", \"Small\", \"Med.\", \"Large\"] * 3\n",
    "\n",
    "ax.xaxis.set_major_locator(FixedLocator(major_ticks))\n",
    "ax.xaxis.set_major_formatter(FixedFormatter(major_labels))\n",
    "ax.xaxis.set_minor_locator(FixedLocator(minor_ticks))\n",
    "ax.xaxis.set_minor_formatter(FixedFormatter(minor_labels))\n",
    "ax.xaxis.grid(False, which=\"major\")\n",
    "# ax.xaxis.grid(True, which='minor')\n",
    "ax.set_xlim(0.5, 16.5)\n",
    "ax.tick_params(axis=\"x\", which=\"major\", length=0, pad=20, labelsize=12)\n",
    "ax.tick_params(axis=\"x\", which=\"minor\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=8)\n",
    "\n",
    "# ax.legend(loc=(0.55,0.04), fontsize=8)\n",
    "\n",
    "# save_fig(f\"{plot_dir}/{dataset}_cov_violin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MPIW plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"#E63946\", \"#219EBC\", \"#023047\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 1.3))\n",
    "\n",
    "data = [mpiw_std, mpiw_ens, mpiw_cqr]\n",
    "means = [d.mean() for d in data]\n",
    "violin = ax.violinplot(data, showextrema=False, widths=0.5, points=1000)\n",
    "\n",
    "for i, body in enumerate(violin[\"bodies\"]):\n",
    "    body.set_facecolor(col[0])\n",
    "    body.set_edgecolor(\"black\")\n",
    "    body.set_alpha(0.8)\n",
    "    body.set_linewidth(1)\n",
    "    \n",
    "    # horizontal mean lines\n",
    "    path = body.get_paths()[0].to_polygons()[0]\n",
    "    ax.plot([min(path[:,0])+0.01, max(path[:,0])-0.01], [means[i], means[i]], color=\"black\", linestyle=\"-\", linewidth=1)\n",
    "\n",
    "ax.set_ylabel(\"MPIW\", fontsize=12)\n",
    "# ax.set_ylim(y_lims[dataset])\n",
    "# ax.set_yticks(y_lims_ticks[dataset])\n",
    "\n",
    "major_ticks = [1,2,3]\n",
    "major_labels = [\"Box-Std\", \"Box-Ens\", \"Box-CQR\"]\n",
    "ax.xaxis.set_major_locator(FixedLocator(major_ticks))\n",
    "ax.xaxis.set_major_formatter(FixedFormatter(major_labels))\n",
    "\n",
    "ax.xaxis.grid(False)\n",
    "ax.tick_params(axis=\"x\", which=\"major\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=8)\n",
    "\n",
    "# save_fig(f\"{plot_dir}/{dataset}_mpiw_violin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Coverage across classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 4\n",
    "class_names = list(util.get_selected_coco_classes().keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_std = data_std[:, classes, i:j].nanmean(dim=2)[:, :, 5].numpy()\n",
    "cov_ens = data_ens[:, classes, i:j].nanmean(dim=2)[:, :, 5].numpy()\n",
    "cov_cqr = data_cqr[:, classes, i:j].nanmean(dim=2)[:, :, 5].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"#E63946\", \"#219EBC\", \"#023047\", \"#A7C957\", \"#386641\", \"#E63946\", \"#219EBC\"]\n",
    "# colors = {conf_str[0]: \"#BC4749\", conf_str[1]: \"#A7C957\", conf_str[2]: \"#386641\"}\n",
    "\n",
    "y_lims = {\"coco_val\": (0.64, 1.02), \"cityscapes\": (0.64, 1.02), \"bdd100k_train\": (0.78, 1.02)}\n",
    "y_lims_ticks = {\"coco_val\": [0.7, 0.8, 0.9, 1.0], \"cityscapes\": [0.7, 0.8, 0.9, 1.0], \"bdd100k_train\": [0.8, 0.9, 1.0]}\n",
    "# leg_loc = {\"coco_val\": (0.55, 0.04)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 1.7))\n",
    "\n",
    "ax.axhline(y=0.9, color=\"black\", linestyle=\"--\", label=r'Target coverage (1 - $\\alpha_B$)')\n",
    "liml, limh = emp_cov_lim[dataset]\n",
    "# ax.axhline(y=liml, color=\"grey\", linestyle=\"-\", label=r'Coverage distr. $Q_{0.01}$')\n",
    "# ax.axhline(y=limh, color=\"grey\", linestyle=\"-\", label=r'Coverage distr. $Q_{0.99}$')\n",
    "ax.axhspan(liml, limh, alpha=0.3, color=\"grey\", label=r'Coverage distribution')\n",
    "\n",
    "data = [cov_std.mean(axis=1), cov_std[:,0], cov_std[:,1], cov_std[:,3], cov_std[:,2], cov_std[:,4], cov_std[:,5], \n",
    "        cov_ens.mean(axis=1), cov_ens[:,0], cov_ens[:,1], cov_ens[:,3], cov_ens[:,2], cov_ens[:,4], cov_ens[:,5],\n",
    "        cov_cqr.mean(axis=1), cov_cqr[:,0], cov_cqr[:,1], cov_cqr[:,3], cov_cqr[:,2], cov_cqr[:,4], cov_cqr[:,5]]\n",
    "means = [d.mean() for d in data]\n",
    "offsets = [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25]\n",
    "violin = ax.violinplot(data, showextrema=False, widths=0.5, points=1000, positions=offsets)\n",
    "\n",
    "for i, body in enumerate(violin[\"bodies\"]):\n",
    "    body.set_facecolor(col[i % len(col)])\n",
    "    body.set_edgecolor(\"black\")\n",
    "    body.set_alpha(0.8)\n",
    "    body.set_linewidth(1)\n",
    "    \n",
    "    # horizontal mean lines\n",
    "    path = body.get_paths()[0].to_polygons()[0]\n",
    "    ax.plot([min(path[:,0])+0.01, max(path[:,0])-0.01], [means[i], means[i]], color=\"black\", linestyle=\"-\", linewidth=1)\n",
    "\n",
    "ax.set_ylabel(\"Coverage\", fontsize=12)\n",
    "ax.set_ylim(y_lims[dataset])\n",
    "ax.set_yticks(y_lims_ticks[dataset])\n",
    "\n",
    "major_ticks = [4.1, 13.1, 22.1]\n",
    "major_labels = [\"Box-Std\", \"Box-Ens\", \"Box-CQR\"]\n",
    "\n",
    "minor_ticks = [1, 2, 3, 4, 5, 6, 7, 10, 11, 12, 13, 14, 15, 16, 19, 20, 21, 22, 23, 24, 25]\n",
    "# minor_labels = [\"$Cov$\", \"$Cov_S$\", \"$Cov_M$\", \"$Cov_L$\"] * 3\n",
    "minor_labels = [\"All\", \"Person\", \"Bicycle\", \"Motorcycle\", \"Car\", \"Bus\", \"Truck\"] * 3\n",
    "\n",
    "ax.xaxis.set_major_locator(FixedLocator(major_ticks))\n",
    "ax.xaxis.set_major_formatter(FixedFormatter(major_labels))\n",
    "ax.xaxis.set_minor_locator(FixedLocator(minor_ticks))\n",
    "ax.xaxis.set_minor_formatter(FixedFormatter(minor_labels))\n",
    "ax.xaxis.grid(False, which=\"major\")\n",
    "# ax.xaxis.grid(True, which='minor')\n",
    "ax.set_xlim(0.5, 25.5)\n",
    "ax.tick_params(axis=\"x\", which=\"major\", length=0, pad=38, labelsize=12)\n",
    "ax.tick_params(axis=\"x\", which=\"minor\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=8)\n",
    "\n",
    "for label in ax.xaxis.get_minorticklabels():\n",
    "    label.set_rotation(40)\n",
    "    label.set_horizontalalignment('right')\n",
    "\n",
    "# ax.legend(loc=(0.55,0.04), fontsize=8)\n",
    "\n",
    "# save_fig(f\"{plot_dir}/{dataset}_cov_class_violin\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: caption lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(0.3, 0.1))\n",
    "ax.plot([0,1], [0.5,0.5], color='black', ls='--', lw=1)\n",
    "ax.axis('off')\n",
    "# save_fig(f\"{plot_dir}/caption_line1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(0.3, 0.1))\n",
    "ax.plot([0,1], [0.5,0.5], color='grey', ls='-', lw=5, alpha=0.7)\n",
    "ax.axis('off')\n",
    "# save_fig(f\"{plot_dir}/caption_line2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: Ours against baselines (one-sided)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_method = \"Oracle\" # ClassThr\n",
    "box_metric = \"mpiw\"\n",
    "baseline_idx = 4 # rows 0-3 are the baseline methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_base = pd.read_csv(\"results/results_selected_base/coco_val_res_base_box_set_table.csv\")\n",
    "city_base = pd.read_csv(\"results/results_selected_base/cityscapes_res_base_box_set_table.csv\")\n",
    "bdd_base = pd.read_csv(\"results/results_selected_base/bdd100k_train_res_base_box_set_table.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_base = coco_base.loc[coco_base[\"label\"].isin([label_method]), [\"conf\", \"label\", box_metric]]\n",
    "city_base = city_base.loc[city_base[\"label\"].isin([label_method]), [\"conf\", \"label\", box_metric]]\n",
    "bdd_base = bdd_base.loc[bdd_base[\"label\"].isin([label_method]), [\"conf\", \"label\", box_metric]]\n",
    "\n",
    "coco_dat = coco_base[box_metric].to_numpy()\n",
    "city_dat = city_base[box_metric].to_numpy()\n",
    "bdd_dat = bdd_base[box_metric].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coco_base, coco_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = [\"#E63946\", \"#023047\"]\n",
    "datasets = [\"COCO\", \"Cityscapes\", \"BDD100k\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(4, 1))\n",
    "bar_width = 0.35\n",
    "index = np.arange(len(datasets))\n",
    "\n",
    "for i, dat in enumerate([coco_dat, city_dat, bdd_dat]):\n",
    "    best_base = dat[:baseline_idx].min()\n",
    "    best_ours = dat[baseline_idx:].min()\n",
    "    \n",
    "    bar_base = ax.bar(i, best_base, bar_width, label='And\\u00E9ol et al.', alpha=0.8, color=col[0])\n",
    "    bar_ours = ax.bar(i + bar_width, best_ours, bar_width, label='Ours', alpha=0.8, color=col[1])\n",
    "    \n",
    "handles, labels = ax.get_legend_handles_labels()\n",
    "# Remove duplicate legend entries\n",
    "by_label = dict(zip(labels, handles))\n",
    "leg = ax.legend(by_label.values(), by_label.keys(), loc=(1.03, 0.15), fontsize=8)\n",
    "leg.get_frame().set_facecolor(\"white\")\n",
    "leg.get_frame().set_edgecolor(\"black\")\n",
    "leg.get_frame().set_alpha(1.0)\n",
    "\n",
    "ax.set_ylabel(\"MPIW ($\\downarrow$)\", fontsize=12)\n",
    "ax.set_yticks([25, 50, 75, 100])\n",
    "ax.set_ylim(60, 110)\n",
    "ax.set_xticks(index + bar_width/2)\n",
    "ax.set_xticklabels(datasets)\n",
    "ax.tick_params(axis='x', which='both', bottom=False, top=False)\n",
    "\n",
    "ax.tick_params(axis=\"x\", which=\"major\", labelsize=8)\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=8)\n",
    "ax.xaxis.grid(False)\n",
    "ax.yaxis.grid(False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# save_fig(\"plots/base_comp_small\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For all comparison methods in appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"COCO\", \"Cityscapes\", \"BDD100k\"]\n",
    "methods = [\"AddBonf\", \"MultBonf\", \"AddMax\", \"MultMax\", \"Box-Std\", \"Box-Ens\", \"Box-Mult\"]\n",
    "num_methods = len(methods)\n",
    "col = [\"#E63946\", \"#E63946\", \"#E63946\", \"#E63946\", \"#023047\", \"#023047\", \"#023047\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 1.8))\n",
    "bar_width = 0.2  # Adjusted bar width\n",
    "dataset_spacing = 0.5  # Space between datasets\n",
    "start_pos = 0.5  # Starting position for the first bar\n",
    "\n",
    "# Create a list for minor ticks and labels\n",
    "minor_ticks = []\n",
    "minor_labels = []\n",
    "\n",
    "for i, dat in enumerate([coco_dat, city_dat, bdd_dat]):\n",
    "    for j in range(num_methods):\n",
    "        # Calculate the position for each bar\n",
    "        pos = start_pos + i * dataset_spacing + j * bar_width\n",
    "        # Example data access, modify as per your data structure\n",
    "        data_value = dat[j]\n",
    "        ax.bar(pos, data_value, bar_width, alpha=0.8, color=col[j], edgecolor=\"black\", linewidth=0.5)\n",
    "        # Add minor tick and label\n",
    "        minor_ticks.append(pos)\n",
    "        if i == 0:  # Add labels only for the first dataset\n",
    "            minor_labels.append(methods[j])\n",
    "    start_pos += bar_width * num_methods  # Update start position for the next dataset\n",
    "\n",
    "ax.set_ylabel(\"MPIW ($\\downarrow$)\", fontsize=12)\n",
    "ax.set_yticks([25, 50, 75, 100, 125])\n",
    "ax.set_ylim(60, 123)\n",
    "\n",
    "# Set major ticks for datasets\n",
    "major_ticks = np.array([1.15, 3.05, 4.95])\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticklabels(datasets, )\n",
    "\n",
    "# Set minor ticks for methods\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_xticklabels(minor_labels * len(datasets), minor=True, fontsize=8, rotation=45)\n",
    "\n",
    "ax.tick_params(axis=\"x\", which=\"major\", labelsize=12, pad=38)\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=8)\n",
    "ax.tick_params(axis='x', which='major', bottom=False, top=False)\n",
    "ax.xaxis.grid(False)\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Uncomment the following line to save the figure\n",
    "# plt.savefig(\"plots/base_comp_mpiw.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\"COCO\", \"Cityscapes\", \"BDD100k\"]\n",
    "methods = [\"AddBonf\", \"MultBonf\", \"AddMax\", \"MultMax\", \"Box-Std\", \"Box-Ens\", \"Box-Mult\"]\n",
    "num_methods = len(methods)\n",
    "col = [\"#E63946\", \"#E63946\", \"#E63946\", \"#E63946\", \"#023047\", \"#023047\", \"#023047\"]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(7.5, 1.8))\n",
    "bar_width = 0.2  # Adjusted bar width\n",
    "dataset_spacing = 0.5  # Space between datasets\n",
    "start_pos = 0.5  # Starting position for the first bar\n",
    "\n",
    "# Create a list for minor ticks and labels\n",
    "minor_ticks = []\n",
    "minor_labels = []\n",
    "\n",
    "for i, dat in enumerate([coco_dat, city_dat, bdd_dat]):\n",
    "    for j in range(num_methods):\n",
    "        # Calculate the position for each bar\n",
    "        pos = start_pos + i * dataset_spacing + j * bar_width\n",
    "        # Example data access, modify as per your data structure\n",
    "        data_value = dat[j]\n",
    "        ax.bar(pos, data_value, bar_width, alpha=0.8, color=col[j], edgecolor=\"black\", linewidth=0.5)\n",
    "        # Add minor tick and label\n",
    "        minor_ticks.append(pos)\n",
    "        if i == 0:  # Add labels only for the first dataset\n",
    "            minor_labels.append(methods[j])\n",
    "    start_pos += bar_width * num_methods  # Update start position for the next dataset\n",
    "\n",
    "ax.set_ylabel(\"Stretch ($\\downarrow$)\", fontsize=12)\n",
    "ax.set_yticks([1.5, 2])\n",
    "ax.set_ylim(1.2, 2.25)\n",
    "\n",
    "# Set major ticks for datasets\n",
    "major_ticks = np.array([1.15, 3.05, 4.95])\n",
    "ax.set_xticks(major_ticks)\n",
    "ax.set_xticklabels(datasets, )\n",
    "\n",
    "# Set minor ticks for methods\n",
    "ax.set_xticks(minor_ticks, minor=True)\n",
    "ax.set_xticklabels(minor_labels * len(datasets), minor=True, fontsize=8, rotation=45)\n",
    "\n",
    "ax.tick_params(axis=\"x\", which=\"major\", labelsize=12, pad=38)\n",
    "ax.tick_params(axis=\"y\", which=\"major\", labelsize=8)\n",
    "ax.tick_params(axis='x', which='major', bottom=False, top=False)\n",
    "ax.xaxis.grid(False)\n",
    "ax.yaxis.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Uncomment the following line to save the figure\n",
    "# plt.savefig(\"plots/base_comp_stretch.png\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: Ablation coverage levels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "dataset = \"bdd100k_train\" #[\"coco_val\", \"cityscapes\", \"bdd100k_train\"]\n",
    "model = \"std_conf_x101fpn_std_rank_class\"\n",
    "score = \"abs_res\"\n",
    "\n",
    "res_folder = f\"/media/atimans/hdd/output_abl/{dataset}\"\n",
    "plot_folder = \"plots/results_ablation\"\n",
    "Path(plot_folder).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_cov = [0.85, 0.90, 0.95]\n",
    "label_cov = [0.8, 0.9, 0.99, 1.0]\n",
    "\n",
    "box_cov_str = [f\"{int(cov*100)}\" for cov in box_cov]\n",
    "label_cov_str = [f\"{int(cov*100)}\" for cov in label_cov]\n",
    "\n",
    "cov_combos = list(itertools.product(box_cov, label_cov))\n",
    "cov_combos_str = list(itertools.product(box_cov_str, label_cov_str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_paths = []\n",
    "box_paths = []\n",
    "\n",
    "for bc, lc in cov_combos_str:\n",
    "    label_paths.append(f\"{res_folder}/{model}_{bc}_{lc}/{model}_{bc}_{lc}_label_table.csv\")\n",
    "    box_paths.append(f\"{res_folder}/{model}_{bc}_{lc}/{model}_{bc}_{lc}_box_set_table_{score}.csv\")\n",
    "\n",
    "print(\"Loading results from:\", res_folder, \"\\n\", \"Plotting figures to:\", plot_folder)\n",
    "print(\"Label result files:\", label_paths, \"\\n\", \"Box result files:\", box_paths)\n",
    "\n",
    "label_path_def = f\"{res_folder}/{model}/{model}_label_table.csv\"\n",
    "box_path_def = f\"{res_folder}/{model}/{model}_box_set_table_{score}.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "box_paths, label_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcov = []\n",
    "leff = []\n",
    "\n",
    "bcov = []\n",
    "beff = []\n",
    "\n",
    "row = 4 # class_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(label_paths):\n",
    "    if i==6: #90, 99 \n",
    "        df = pd.read_csv(label_path_def)\n",
    "    else:\n",
    "        df = pd.read_csv(p)\n",
    "    \n",
    "    lcov.append(df[\"cov set\"].iloc[row].item())\n",
    "    leff.append(df[\"mean set size\"].iloc[row].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, p in enumerate(box_paths):\n",
    "    if i==6: #90, 99 \n",
    "        df = pd.read_csv(box_path_def)\n",
    "    else:\n",
    "        df = pd.read_csv(p)\n",
    "    \n",
    "    bcov.append(df[\"cov box\"].iloc[row].item())\n",
    "    beff.append(df[\"mpiw\"].iloc[row].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(lcov, leff, bcov, beff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"0.8\":\"#E63946\", \"0.9\":\"#219EBC\", \"0.99\":\"#023047\", \"1.0\":\"#A7C957\"}\n",
    "markers = {\"0.85\":\"o\", \"0.9\":\"*\", \"0.95\":\"^\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "\n",
    "for i, (bc, lc) in enumerate(cov_combos):\n",
    "    ax.scatter(lcov[i], bcov[i], color=colors[str(lc)], marker=markers[str(bc)], alpha=0.8, label=fr\"$(1-\\alpha_B)=${bc}, $(1-\\alpha_L)$={lc}\", linewidth=1, s=48)\n",
    "\n",
    "for xtick in label_cov:\n",
    "    ax.axvline(x=xtick, color='black', linestyle=':', linewidth=1, alpha=0.6)\n",
    "\n",
    "for ytick in box_cov:\n",
    "    ax.axhline(y=ytick, color='black', linestyle=':', linewidth=1, alpha=0.6)\n",
    "\n",
    "ax.set_ylabel(r'Box cov.', fontsize=10)\n",
    "ax.set_xlabel(r'Label cov.', fontsize=10)\n",
    "\n",
    "ax.set_xticks([0.8, 0.9, 1.0])\n",
    "ax.set_yticks(box_cov)\n",
    "\n",
    "ax.yaxis.grid(False, which=\"major\")\n",
    "ax.xaxis.grid(False, which=\"major\")\n",
    "\n",
    "ax.set_xlim(0.75, 1.05)\n",
    "ax.set_ylim(0.8, 1.0)\n",
    "\n",
    "# leg = ax.legend(ncol=3, loc=(1.03, 0.15), fontsize=8)\n",
    "# leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "# leg.get_frame().set_alpha(1.0)\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"{plot_folder}/{dataset}_{score}_covs.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "\n",
    "for i, (bc, lc) in enumerate(cov_combos):\n",
    "    ax.scatter(leff[i], beff[i], color=colors[str(lc)], marker=markers[str(bc)], alpha=0.8, label=fr\"$(1-\\alpha_B)=${bc}, $(1-\\alpha_L)$={lc}\", linewidth=1, s=48)\n",
    "\n",
    "# for xtick in label_cov:\n",
    "#     ax.axvline(x=xtick, color='black', linestyle=':', linewidth=1, alpha=0.6)\n",
    "\n",
    "# for ytick in box_cov:\n",
    "#     ax.axhline(y=ytick, color='black', linestyle=':', linewidth=1, alpha=0.6)\n",
    "\n",
    "ax.set_ylabel(r'MPIW', fontsize=10)\n",
    "ax.set_xlabel(r'Mean set size', fontsize=10)\n",
    "\n",
    "# ax.set_xticks([1, 2, 3, 4])\n",
    "# ax.set_yticks([])\n",
    "\n",
    "ax.yaxis.grid(True, which=\"major\")\n",
    "ax.xaxis.grid(True, which=\"major\")\n",
    "\n",
    "ax.set_xlim(0.5, 7.5)\n",
    "ax.set_ylim(65, 215)\n",
    "\n",
    "# leg = ax.legend(ncol=3, loc=(1.03, 0.15), fontsize=8)\n",
    "# leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "# leg.get_frame().set_alpha(1.0)\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"{plot_folder}/{dataset}_{score}_eff.png\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot: Set size and MPIW vs. misclassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets\n",
    "dataset = \"coco_val\" #[\"coco_val\", \"cityscapes\", \"bdd100k_train\"]\n",
    "\n",
    "res_folder = f\"../../../../media/atimans/hdd/output/{dataset}\"\n",
    "plot_folder = \"plots\"\n",
    "Path(plot_folder).mkdir(exist_ok=True, parents=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [(\"std\", \"abs\"), (\"ens\", \"norm\"), (\"cqr\", \"quant\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_paths = []\n",
    "box_paths = []\n",
    "\n",
    "for method, score in methods:\n",
    "    label_paths.append(f\"{res_folder}/{method}_conf_x101fpn_{method}_rank_class/{method}_conf_x101fpn_{method}_rank_class_label_table.csv\")\n",
    "    box_paths.append(f\"{res_folder}/{method}_conf_x101fpn_{method}_rank_class/{method}_conf_x101fpn_{method}_rank_class_box_set_table_{score}_res.csv\")\n",
    "\n",
    "print(label_paths, \"\\n\", box_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "lcov_cl, lcov_miscl = [], []\n",
    "leff_cl, leff_miscl = [], []\n",
    "\n",
    "bcov_cl, bcov_miscl = [], []\n",
    "beff_cl, beff_miscl = [], []\n",
    "\n",
    "row = 4 # class_selected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in label_paths:\n",
    "    df = pd.read_csv(p)\n",
    "    lcov_cl.append(df[\"cov set cl\"].iloc[row].item())\n",
    "    lcov_miscl.append(df[\"cov set miscl\"].iloc[row].item())\n",
    "    leff_cl.append(df[\"mean set size cl\"].iloc[row].item())\n",
    "    leff_miscl.append(df[\"mean set size miscl\"].iloc[row].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in box_paths:\n",
    "    df = pd.read_csv(p)\n",
    "    bcov_cl.append(df[\"cov box cl\"].iloc[row].item())\n",
    "    bcov_miscl.append(df[\"cov box miscl\"].iloc[row].item())\n",
    "    beff_cl.append(df[\"mpiw cl\"].iloc[row].item())\n",
    "    beff_miscl.append(df[\"mpiw miscl\"].iloc[row].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Label cov cl:\", lcov_cl, \"\\n\", \"Label cov miscl:\", lcov_miscl, \"\\n\", \"Label eff cl:\", leff_cl, \"\\n\", \"Label eff miscl:\", leff_miscl)\n",
    "print(\"Box cov cl:\", bcov_cl, \"\\n\", \"Box cov miscl:\", bcov_miscl, \"\\n\", \"Box eff cl:\", beff_cl, \"\\n\", \"Box eff miscl:\", beff_miscl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\"Classif.\":\"#023047\", \"Misclassif.\":\"#E63946\"}\n",
    "markers = {\"Box-Std\":\"o\", \"Box-Ens\":\"*\", \"Box-CQR\":\"^\"}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2, 2))\n",
    "\n",
    "for i, m in enumerate(markers.keys()):\n",
    "    ax.scatter(lcov_cl[i], bcov_cl[i], color=colors[\"Classif.\"], marker=markers[m], alpha=0.8, label=m, linewidth=1, s=48)\n",
    "    ax.scatter(lcov_miscl[i], bcov_miscl[i], color=colors[\"Misclassif.\"], marker=markers[m], alpha=0.8, linewidth=1, s=48)\n",
    "\n",
    "ax.set_ylabel(r'Box cov.', fontsize=10)\n",
    "ax.set_xlabel(r'Label cov.', fontsize=10)\n",
    "\n",
    "# ax.set_xticks([0.8, 0.9, 1.0])\n",
    "# ax.set_yticks([0.8, 0.9, 1.0])\n",
    "\n",
    "# ax.yaxis.grid(False, which=\"major\")\n",
    "# ax.xaxis.grid(False, which=\"major\")\n",
    "ax.set_ylim(0.92, 0.96)\n",
    "ax.set_xlim(0.98, 1.01)\n",
    "\n",
    "# leg = ax.legend(ncol=3, loc=(1.03, 0.15), fontsize=8)\n",
    "# leg.get_frame().set_facecolor(\"white\")\n",
    "# leg.get_frame().set_edgecolor(\"black\")\n",
    "# leg.get_frame().set_alpha(1.0)\n",
    "ax.legend()\n",
    "\n",
    "plt.xticks(fontsize=8)\n",
    "plt.yticks(fontsize=8)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"{plot_folder}/{dataset}_{score}_covs.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.lines as mlines\n",
    "\n",
    "colors = {\"Classif.\":\"#023047\", \"Misclassif.\":\"#E63946\"}\n",
    "markers = {\"Box-Std\":\"o\", \"Box-Ens\":\"*\", \"Box-CQR\":\"^\"}\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(1.8, 1.5))\n",
    "\n",
    "# Scatter plots for actual data\n",
    "for i, m in enumerate(markers.keys()):\n",
    "    ax.scatter(leff_cl[i], beff_cl[i], color=colors[\"Classif.\"], marker=markers[m], alpha=0.8, linewidth=1, s=48)\n",
    "    ax.scatter(leff_miscl[i], beff_miscl[i], color=colors[\"Misclassif.\"], marker=markers[m], alpha=0.8, linewidth=1, s=48)\n",
    "\n",
    "# Setting labels and limits\n",
    "ax.set_ylabel(r'MPIW', fontsize=8, labelpad=-3)\n",
    "ax.set_xlabel(r'Mean set size', fontsize=8, labelpad=0)\n",
    "ax.set_ylim(78, 104)\n",
    "ax.set_xlim(1.9, 3.3)\n",
    "\n",
    "# Create custom handles for the marker type legend (all grey)\n",
    "marker_handles = [mlines.Line2D([], [], color='grey', marker=markers[m], linestyle='None', markersize=6, label=m) for m in markers]\n",
    "\n",
    "# Add the marker type legend to the plot\n",
    "leg_markers = ax.legend(handles=marker_handles, loc='upper right', fontsize=6)\n",
    "\n",
    "# Create handles for the color legend\n",
    "classif_handle = mlines.Line2D([], [], color=colors[\"Classif.\"], marker='s', linestyle='None', markersize=5, label='Classif.')\n",
    "misclassif_handle = mlines.Line2D([], [], color=colors[\"Misclassif.\"], marker='s', linestyle='None', markersize=5, label='Misclassif.')\n",
    "\n",
    "# Add the color legend to the plot\n",
    "ax.legend(handles=[classif_handle, misclassif_handle], loc='lower left', fontsize=6)\n",
    "\n",
    "# Manually add the first legend back to the plot\n",
    "ax.add_artist(leg_markers)\n",
    "\n",
    "plt.xticks(fontsize=6)\n",
    "plt.yticks(fontsize=6)\n",
    "plt.tight_layout()\n",
    "\n",
    "# plt.savefig(f\"{plot_folder}/{dataset}_size_vs_misclassif.png\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_cu121",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
